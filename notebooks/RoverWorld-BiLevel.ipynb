{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a014ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling BiMDPs [8af17bd5-7ea0-4ae2-8fd5-dbf3cdd18bce]\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using BiMDPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3746890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"case002\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"case002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de37bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiMDPs.RoverWorld.RoverWorldMDP\n",
       "  grid_size: Tuple{Int64, Int64}\n",
       "  max_time: Int64 20\n",
       "  null_xy: Tuple{Int64, Int64}\n",
       "  p_transition: Float64 1.0\n",
       "  γ: Float64 0.95\n",
       "  tgts: Dict{Int64, Tuple{Tuple{Int64, Int64}, Tuple{Int64, Int64}, Float64}}\n",
       "  obstacles: Array{Tuple{Tuple{Int64, Int64}, Tuple{Int64, Int64}, Float64}}((1,))\n",
       "  exit_xys: Array{Tuple{Int64, Int64}}((0,))\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgw = case_dictionary[dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f025df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "023ad03f",
   "metadata": {},
   "source": [
    "## Testing LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04b5fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed\n",
      "========== LLRoverWorldMDP ==========\n",
      "grid_size: (20, 20)\n",
      "max_time: 10\n",
      "null_xy: (-1, -1)\n",
      "p_transition: 1.0\n",
      "γ: 0.95\n",
      "current_tgt: ((5, 1), (1, 10), 50.0)\n",
      "obstacles: [((3, 1), (1, 10), -5.0)]\n",
      "exit_xys: Tuple{Int64, Int64}[]\n",
      "init_state: BiMDPs.LLRoverWorld.LLState(2, 6, 1)\n",
      "=====================================\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 6, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 5, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 4, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 3, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 1, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 1, 9), taking action UP, received reward 50.0\n"
     ]
    }
   ],
   "source": [
    "BiMDPs.test_LL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1756894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0bf457b",
   "metadata": {},
   "source": [
    "## Plot rewards grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f80f98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"case002/reward_evolution.gif\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoverWorld.create_reward_field_evolution_gif(rgw; dir=dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ff045",
   "metadata": {},
   "source": [
    "## Construct bi-level MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022ac0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BiMDPs.HLRoverWorld.HLRoverWorldMDP\n",
       "  grid_size: Tuple{Int64, Int64}\n",
       "  max_time: Int64 20\n",
       "  null_xy: Tuple{Int64, Int64}\n",
       "  γ: Float64 0.95\n",
       "  tgts: Dict{Int64, Tuple{Tuple{Int64, Int64}, Tuple{Int64, Int64}, Float64}}\n",
       "  exit_xys: Array{Tuple{Int64, Int64}}((0,))\n",
       ", DiscreteValueIteration.ValueIterationPolicy{Matrix{Float64}, Vector{Float64}, Vector{Int64}, BiMDPs.HLRoverWorld.HLAction, BiMDPs.HLRoverWorld.HLRoverWorldMDP}([92.625 47.5; 92.625 47.5; … ; 0.0 0.0; 0.0 0.0], [92.625, 92.625, 47.5, 47.5, 47.5, 47.5, 47.5, 47.5, 88.2253125, 47.5  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], BiMDPs.HLRoverWorld.HLAction[BiMDPs.HLRoverWorld.HLAction(1), BiMDPs.HLRoverWorld.HLAction(2)], true, BiMDPs.HLRoverWorld.HLRoverWorldMDP\n",
       "  grid_size: Tuple{Int64, Int64}\n",
       "  max_time: Int64 20\n",
       "  null_xy: Tuple{Int64, Int64}\n",
       "  γ: Float64 0.95\n",
       "  tgts: Dict{Int64, Tuple{Tuple{Int64, Int64}, Tuple{Int64, Int64}, Float64}}\n",
       "  exit_xys: Array{Tuple{Int64, Int64}}((0,))\n",
       "))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_mdp, hl_policy = convert_to_bilevel(rgw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7acf3",
   "metadata": {},
   "source": [
    "## View stepthrough of one HL policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa052152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " (s = BiMDPs.HLRoverWorld.HLState(6, 7, 1, Bool[0, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 9, Bool[0, 0]), a = BiMDPs.HLRoverWorld.HLAction(2), r = 50.0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 8, 15, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 50.0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = HLRoverWorld.HLState(6,7,1,fill(false, length(rgw.tgts)))\n",
    "steps = HLRoverWorld.collect_stepthrough(hl_mdp, hl_policy, init_state = s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e8634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undiscounted reward was 100.0.\n"
     ]
    }
   ],
   "source": [
    "rsum = sum(st.r for st in steps)\n",
    "println(\"Undiscounted reward was $rsum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27782a",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b385b19c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Any}:\n",
       " (s = BiMDPs.HLRoverWorld.HLState(1, 9, 1, Bool[0, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[0, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 50.0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)\n",
       " (s = BiMDPs.HLRoverWorld.HLState(9, 2, 16, Bool[1, 0]), a = BiMDPs.HLRoverWorld.HLAction(1), r = 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0 = HLRoverWorld.HLState(1,9,1,fill(false, length(rgw.tgts)))\n",
    "steps = HLRoverWorld.collect_stepthrough(hl_mdp, hl_policy, init_state = s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31cc813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undiscounted reward was 50.0.\n"
     ]
    }
   ],
   "source": [
    "rsum = sum(st.r for st in steps)\n",
    "println(\"Undiscounted reward was $rsum.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071bbc8",
   "metadata": {},
   "source": [
    "## From a non-starting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "384574fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state BiMDPs.HLRoverWorld.HLState(9, 8, 10, Bool[0, 0, 0]) is out of bounds.\n"
     ]
    }
   ],
   "source": [
    "s0 = HLRoverWorld.HLState(9,8,10,Bool[0,0,0])\n",
    "steps = HLRoverWorld.collect_stepthrough(hl_mdp, hl_policy, init_state = s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83388eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state BiMDPs.HLRoverWorld.HLState(9, 7, 9, Bool[0, 0, 0]) is out of bounds.\n"
     ]
    }
   ],
   "source": [
    "s0 = HLRoverWorld.HLState(9,7,9,Bool[0,0,0])\n",
    "steps = HLRoverWorld.collect_stepthrough(hl_mdp, hl_policy, init_state = s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14718091",
   "metadata": {},
   "source": [
    "## Compare optimality vs computation time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20e95fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = optimality_vs_compute(rgw, [(\"bl_vi\", [1, 5], 500), (\"vi\", [1, 5], 500), (\"qlearning\", [50,50000], 500), (\"sarsa\", [50,50000], 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e934eb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of HL part of bl_vi after 50 iterations: 0.099736\n",
      "Comp_time of HL part of bl_vi after 50 iterations: 0.099736\n",
      "Simulation 1\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(6, 10, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(6, 10, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0502417\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 10, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 9, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 8, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 7, 4), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 7, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 6, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 5, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 4, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 3, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.045196\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0498755\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0565358\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 1: 100.0\n",
      "Simulation 2\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(6, 4, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(6, 4, 1, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0423786\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 3), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 5), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 5, 7), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 6, 8), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 7, 9), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 8, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 8, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 12), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 13), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 14), taking action LEFT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 8, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 8, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0476731\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 10), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 11), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 13), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0538469\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0443215\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 2: 150.0\n",
      "Simulation 3\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(2, 7, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(2, 7, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0491072\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 7, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 6, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 5, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 4, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 3, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 12), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0565806\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0502341\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0494346\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 3: 100.0\n",
      "Simulation 4\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(5, 8, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(5, 8, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0519347\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 8, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 7, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 6, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 5, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 4, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 3, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0446324\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0493213\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.057111\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 4: 100.0\n",
      "Simulation 5\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(3, 6, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(3, 6, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0473108\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 6, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 5, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 4, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 3, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0489774\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0550333\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0491738\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 5: 100.0\n",
      "Simulation 6\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(7, 8, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(7, 8, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0461925\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 8, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 7, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 6, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 5, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 4, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 3, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 9), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 9, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 9, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0540815\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 9), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 15, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 15, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0456534\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0480894\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 6: 100.0\n",
      "Simulation 7\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 9, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 9, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0575342\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0472024\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0462913\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0556261\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0444583\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0456152\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0529235\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0473579\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0467064\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0542528\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0510974\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0478562\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0552832\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0482671\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0501924\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0543466\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0453139\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0479976\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0534024\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0477605\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "Rewards for simulation 7: 1000.0\n",
      "Simulation 8\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(10, 4, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(10, 4, 1, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0464127\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 4, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 5, 2), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 6, 3), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 7, 4), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 5), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 9, 6), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 7), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 8), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 9), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 9, 13), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 14), taking action LEFT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 6, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 6, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0564798\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 10), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 11), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0444402\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0496329\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0580369\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 8: 150.0\n",
      "Simulation 9\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(2, 6, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(2, 6, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0455765\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 6, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 5, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 4, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 3, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 12, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0468793\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 18, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0531968\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0522983\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 9: 100.0\n",
      "Simulation 10\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(3, 1, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(3, 1, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0498788\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 1, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 2), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 3), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 4), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0570533\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0510479\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0516175\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0557546\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0463478\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0524714\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0590609\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0506108\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0498926\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0551118\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0487582\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0487793\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0532169\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0463184\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.046168\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0518289\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0495853\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.0550864\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 50 iterations: 0.048257\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 8), taking action UP, received reward 50.0\n",
      "Rewards for simulation 10: 1000.0\n",
      "Adding a mean time for LL comp: 0.36722216999999996\n",
      "Reward of bl_vi after 10 simulations: μ = 290.0, σ = 374.7591819348052\n",
      "Comp_time of HL part of bl_vi after 100 iterations: 0.1046424\n",
      "Comp_time of HL part of bl_vi after 100 iterations: 0.1046424\n",
      "Simulation 1\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(6, 5, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(6, 5, 1, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0467824\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 2), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 4), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 6), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 4, 8), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 5, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 5, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 6, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 7, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 8, 13), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 8, 14), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 7, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 7, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0547417\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 10), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 11), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0497778\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0515417\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0538923\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 1: 150.0\n",
      "Simulation 2\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(2, 8, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(2, 8, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0484973\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 8, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 7, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 6, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 5, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 4, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 3, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 12), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 13), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0452725\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0503251\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 2: 100.0\n",
      "Simulation 3\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(10, 3, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(10, 3, 1, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0470302\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 3, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 4, 2), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 5, 3), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 6, 4), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 7, 5), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 6), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 9, 7), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 8), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 9), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 10, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 9, 13), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 8, 14), taking action LEFT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 7, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 7, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0465155\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 10), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 11), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0551894\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0478624\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0502422\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 3: 150.0\n",
      "Simulation 4\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(5, 4, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(5, 4, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.053941\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 4, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 3, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 3), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 4), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0529617\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0470575\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0553937\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0482596\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0464794\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 100 iterations: 0.052771\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0505652\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0470413\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0577714\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0460842\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0467843\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0526361\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0448792\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0581872\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0449166\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.052688\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0555978\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0437784\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0465029\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "Rewards for simulation 4: 1000.0\n",
      "Simulation 5\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(1, 6, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(1, 6, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0562242\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 6, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 5, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 4, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 3, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 11), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 12), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 13, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0450927\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 19, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0464665\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.055981\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 5: 100.0\n",
      "Simulation 6\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(7, 10, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(7, 10, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0458169\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 10, 1), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 9, 2), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 8, 3), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 7, 4), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 6, 5), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 5, 6), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 4, 7), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 3, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 10), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 11, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0432982\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 17, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0553686\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0451029\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 6: 100.0\n",
      "Simulation 7\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(3, 2, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(3, 2, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0473185\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 1), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 2), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 3), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 4), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0566675\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0454552\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0505964\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.054021\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.047602\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0490169\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0527709\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0468264\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0486887\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0535467\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0486705\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0455508\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0540271\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0504652\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0471619\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0527826\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0507194\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0481757\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 7, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0574845\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 7), taking action UP, received reward 50.0\n",
      "Rewards for simulation 7: 1000.0\n",
      "Simulation 8\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(10, 2, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(10, 2, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0493784\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(10, 2, 1), taking action LEFT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 2), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 2, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 2, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0452236\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 2), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 3), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 4), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 5), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 6), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 7), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 8), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 9), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 13), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 14), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 15), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 8, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 8, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0563964\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 8), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 9), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 10), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 11), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 12), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 13), taking action DOWN, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 14, Bool[1, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0489537\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0534607\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 8: 200.0\n",
      "Simulation 9\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(1, 1, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(1, 1, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0557469\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 1, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(1, 2, 2), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(2, 2, 3), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(3, 2, 4), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(4, 2, 5), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(5, 2, 6), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(6, 2, 7), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 8), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 9), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 10), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 10, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(2), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 10, Bool[0, 0]) to do action ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp tgt: ((9, 8), (15, 20), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0470448\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 10), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 3, 11), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 4, 12), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 5, 13), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 6, 14), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 7, 15), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 16), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 16, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 16, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0501731\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 16), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 9, 17), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 18), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 19), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 10, 20), taking action UP, received reward 0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 8, 20, Bool[1, 1]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0562225\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 8, 20), taking action UP, received reward 0\n",
      "Rewards for simulation 9: 100.0\n",
      "Simulation 10\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(7, 1, 1, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(7, 1, 1, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.051099\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 1, 1), taking action UP, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(7, 2, 2), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(8, 2, 3), taking action RIGHT, received reward 0\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[0, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 50.0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[0, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0461326\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0531035\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0467363\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0487425\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0535387\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0474043\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0486798\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0540706\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0469148\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0479491\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0518653\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0490146\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0462061\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0562964\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.045268\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0531705\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0455953\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0481721\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "HL: in state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]), taking action BiMDPs.HLRoverWorld.HLAction(1), received reward 0\n",
      "Creating LL MDP from state BiMDPs.HLRoverWorld.HLState(9, 2, 4, Bool[1, 0]) to do action ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp tgt: ((9, 2), (1, 18), 50.0)\n",
      "ll_mdp obstacles: [((6, 6), (1, 20), -5.0)]\n",
      "ll_mdp exit_xys: Tuple{Int64, Int64}[]\n",
      "Comp_time of LL part of bl_vi after 100 iterations: 0.0545449\n",
      "LL: in state BiMDPs.LLRoverWorld.LLState(9, 2, 4), taking action UP, received reward 50.0\n",
      "Rewards for simulation 10: 1000.0\n",
      "Adding a mean time for LL comp: 0.45099703999999996\n",
      "Reward of bl_vi after 10 simulations: μ = 390.0, σ = 422.16373863966834\n",
      "Comp_time of vi after 1 iterations: 0.0428039\n",
      "Reward of vi after 500 simulations: μ = 1.15459544375, σ = 8.17606364263525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp_time of vi after 5 iterations: 0.175366\n",
      "Reward of vi after 500 simulations: μ = 23.313311830068724, σ = 29.160799342361408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String, Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}}} with 2 entries:\n",
       "  \"vi\"    => ([0.0428039, 0.175366], [1.1546, 23.3133], [8.17606, 29.1608])\n",
       "  \"bl_vi\" => ([0.466958, 0.555639], [290.0, 390.0], [374.759, 422.164])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = optimality_vs_compute(rgw, [(\"bl_vi\", [50, 100], 10), (\"vi\", [1, 5], 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4c47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = optimality_vs_compute(rgw, [(\"bl_vi\", [1, 5, 50, 100, 150], 500), (\"vi\", [1, 5, 50, 100, 150], 500), (\"qlearning\", [50,50000], 500), (\"sarsa\", [50,50000], 500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90c7579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip210\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip211\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M235.283 1423.18 L2352.76 1423.18 L2352.76 123.472 L235.283 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip212\">\n",
       "    <rect x=\"235\" y=\"123\" width=\"2118\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"502.724,1423.18 502.724,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"853.608,1423.18 853.608,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1204.49,1423.18 1204.49,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1555.38,1423.18 1555.38,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1906.26,1423.18 1906.26,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2257.14,1423.18 2257.14,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1423.18 2352.76,1423.18 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"502.724,1423.18 502.724,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"853.608,1423.18 853.608,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1204.49,1423.18 1204.49,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1555.38,1423.18 1555.38,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1906.26,1423.18 1906.26,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2257.14,1423.18 2257.14,1404.28 \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M480.722 1454.1 Q477.111 1454.1 475.282 1457.66 Q473.477 1461.2 473.477 1468.33 Q473.477 1475.44 475.282 1479.01 Q477.111 1482.55 480.722 1482.55 Q484.356 1482.55 486.162 1479.01 Q487.99 1475.44 487.99 1468.33 Q487.99 1461.2 486.162 1457.66 Q484.356 1454.1 480.722 1454.1 M480.722 1450.39 Q486.532 1450.39 489.588 1455 Q492.666 1459.58 492.666 1468.33 Q492.666 1477.06 489.588 1481.67 Q486.532 1486.25 480.722 1486.25 Q474.912 1486.25 471.833 1481.67 Q468.778 1477.06 468.778 1468.33 Q468.778 1459.58 471.833 1455 Q474.912 1450.39 480.722 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M500.884 1479.7 L505.768 1479.7 L505.768 1485.58 L500.884 1485.58 L500.884 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M516.763 1481.64 L524.402 1481.64 L524.402 1455.28 L516.092 1456.95 L516.092 1452.69 L524.356 1451.02 L529.032 1451.02 L529.032 1481.64 L536.671 1481.64 L536.671 1485.58 L516.763 1485.58 L516.763 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M831.791 1454.1 Q828.18 1454.1 826.352 1457.66 Q824.546 1461.2 824.546 1468.33 Q824.546 1475.44 826.352 1479.01 Q828.18 1482.55 831.791 1482.55 Q835.426 1482.55 837.231 1479.01 Q839.06 1475.44 839.06 1468.33 Q839.06 1461.2 837.231 1457.66 Q835.426 1454.1 831.791 1454.1 M831.791 1450.39 Q837.601 1450.39 840.657 1455 Q843.736 1459.58 843.736 1468.33 Q843.736 1477.06 840.657 1481.67 Q837.601 1486.25 831.791 1486.25 Q825.981 1486.25 822.902 1481.67 Q819.847 1477.06 819.847 1468.33 Q819.847 1459.58 822.902 1455 Q825.981 1450.39 831.791 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M851.953 1479.7 L856.837 1479.7 L856.837 1485.58 L851.953 1485.58 L851.953 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M871.05 1481.64 L887.37 1481.64 L887.37 1485.58 L865.425 1485.58 L865.425 1481.64 Q868.087 1478.89 872.671 1474.26 Q877.277 1469.61 878.458 1468.27 Q880.703 1465.74 881.583 1464.01 Q882.485 1462.25 882.485 1460.56 Q882.485 1457.8 880.541 1456.07 Q878.62 1454.33 875.518 1454.33 Q873.319 1454.33 870.865 1455.09 Q868.435 1455.86 865.657 1457.41 L865.657 1452.69 Q868.481 1451.55 870.935 1450.97 Q873.388 1450.39 875.425 1450.39 Q880.796 1450.39 883.99 1453.08 Q887.185 1455.77 887.185 1460.26 Q887.185 1462.39 886.374 1464.31 Q885.587 1466.2 883.481 1468.8 Q882.902 1469.47 879.8 1472.69 Q876.698 1475.88 871.05 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1182.2 1454.1 Q1178.59 1454.1 1176.76 1457.66 Q1174.96 1461.2 1174.96 1468.33 Q1174.96 1475.44 1176.76 1479.01 Q1178.59 1482.55 1182.2 1482.55 Q1185.84 1482.55 1187.64 1479.01 Q1189.47 1475.44 1189.47 1468.33 Q1189.47 1461.2 1187.64 1457.66 Q1185.84 1454.1 1182.2 1454.1 M1182.2 1450.39 Q1188.01 1450.39 1191.07 1455 Q1194.15 1459.58 1194.15 1468.33 Q1194.15 1477.06 1191.07 1481.67 Q1188.01 1486.25 1182.2 1486.25 Q1176.39 1486.25 1173.31 1481.67 Q1170.26 1477.06 1170.26 1468.33 Q1170.26 1459.58 1173.31 1455 Q1176.39 1450.39 1182.2 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1202.36 1479.7 L1207.25 1479.7 L1207.25 1485.58 L1202.36 1485.58 L1202.36 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1231.6 1466.95 Q1234.96 1467.66 1236.83 1469.93 Q1238.73 1472.2 1238.73 1475.53 Q1238.73 1480.65 1235.21 1483.45 Q1231.69 1486.25 1225.21 1486.25 Q1223.03 1486.25 1220.72 1485.81 Q1218.43 1485.39 1215.97 1484.54 L1215.97 1480.02 Q1217.92 1481.16 1220.23 1481.74 Q1222.55 1482.32 1225.07 1482.32 Q1229.47 1482.32 1231.76 1480.58 Q1234.08 1478.84 1234.08 1475.53 Q1234.08 1472.48 1231.92 1470.77 Q1229.79 1469.03 1225.97 1469.03 L1221.95 1469.03 L1221.95 1465.19 L1226.16 1465.19 Q1229.61 1465.19 1231.44 1463.82 Q1233.27 1462.43 1233.27 1459.84 Q1233.27 1457.18 1231.37 1455.77 Q1229.49 1454.33 1225.97 1454.33 Q1224.05 1454.33 1221.85 1454.75 Q1219.65 1455.16 1217.02 1456.04 L1217.02 1451.88 Q1219.68 1451.14 1221.99 1450.77 Q1224.33 1450.39 1226.39 1450.39 Q1231.71 1450.39 1234.82 1452.83 Q1237.92 1455.23 1237.92 1459.35 Q1237.92 1462.22 1236.27 1464.21 Q1234.63 1466.18 1231.6 1466.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1532.52 1454.1 Q1528.91 1454.1 1527.08 1457.66 Q1525.27 1461.2 1525.27 1468.33 Q1525.27 1475.44 1527.08 1479.01 Q1528.91 1482.55 1532.52 1482.55 Q1536.15 1482.55 1537.96 1479.01 Q1539.79 1475.44 1539.79 1468.33 Q1539.79 1461.2 1537.96 1457.66 Q1536.15 1454.1 1532.52 1454.1 M1532.52 1450.39 Q1538.33 1450.39 1541.38 1455 Q1544.46 1459.58 1544.46 1468.33 Q1544.46 1477.06 1541.38 1481.67 Q1538.33 1486.25 1532.52 1486.25 Q1526.71 1486.25 1523.63 1481.67 Q1520.57 1477.06 1520.57 1468.33 Q1520.57 1459.58 1523.63 1455 Q1526.71 1450.39 1532.52 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1552.68 1479.7 L1557.56 1479.7 L1557.56 1485.58 L1552.68 1485.58 L1552.68 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1580.6 1455.09 L1568.79 1473.54 L1580.6 1473.54 L1580.6 1455.09 M1579.37 1451.02 L1585.25 1451.02 L1585.25 1473.54 L1590.18 1473.54 L1590.18 1477.43 L1585.25 1477.43 L1585.25 1485.58 L1580.6 1485.58 L1580.6 1477.43 L1564.99 1477.43 L1564.99 1472.92 L1579.37 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1884.14 1454.1 Q1880.53 1454.1 1878.7 1457.66 Q1876.9 1461.2 1876.9 1468.33 Q1876.9 1475.44 1878.7 1479.01 Q1880.53 1482.55 1884.14 1482.55 Q1887.78 1482.55 1889.58 1479.01 Q1891.41 1475.44 1891.41 1468.33 Q1891.41 1461.2 1889.58 1457.66 Q1887.78 1454.1 1884.14 1454.1 M1884.14 1450.39 Q1889.95 1450.39 1893.01 1455 Q1896.09 1459.58 1896.09 1468.33 Q1896.09 1477.06 1893.01 1481.67 Q1889.95 1486.25 1884.14 1486.25 Q1878.33 1486.25 1875.25 1481.67 Q1872.2 1477.06 1872.2 1468.33 Q1872.2 1459.58 1875.25 1455 Q1878.33 1450.39 1884.14 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1904.3 1479.7 L1909.19 1479.7 L1909.19 1485.58 L1904.3 1485.58 L1904.3 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1919.42 1451.02 L1937.78 1451.02 L1937.78 1454.96 L1923.7 1454.96 L1923.7 1463.43 Q1924.72 1463.08 1925.74 1462.92 Q1926.76 1462.73 1927.78 1462.73 Q1933.56 1462.73 1936.94 1465.9 Q1940.32 1469.08 1940.32 1474.49 Q1940.32 1480.07 1936.85 1483.17 Q1933.38 1486.25 1927.06 1486.25 Q1924.88 1486.25 1922.61 1485.88 Q1920.37 1485.51 1917.96 1484.77 L1917.96 1480.07 Q1920.05 1481.2 1922.27 1481.76 Q1924.49 1482.32 1926.97 1482.32 Q1930.97 1482.32 1933.31 1480.21 Q1935.65 1478.1 1935.65 1474.49 Q1935.65 1470.88 1933.31 1468.77 Q1930.97 1466.67 1926.97 1466.67 Q1925.09 1466.67 1923.22 1467.08 Q1921.36 1467.5 1919.42 1468.38 L1919.42 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2234.45 1454.1 Q2230.84 1454.1 2229.01 1457.66 Q2227.2 1461.2 2227.2 1468.33 Q2227.2 1475.44 2229.01 1479.01 Q2230.84 1482.55 2234.45 1482.55 Q2238.08 1482.55 2239.89 1479.01 Q2241.72 1475.44 2241.72 1468.33 Q2241.72 1461.2 2239.89 1457.66 Q2238.08 1454.1 2234.45 1454.1 M2234.45 1450.39 Q2240.26 1450.39 2243.31 1455 Q2246.39 1459.58 2246.39 1468.33 Q2246.39 1477.06 2243.31 1481.67 Q2240.26 1486.25 2234.45 1486.25 Q2228.64 1486.25 2225.56 1481.67 Q2222.5 1477.06 2222.5 1468.33 Q2222.5 1459.58 2225.56 1455 Q2228.64 1450.39 2234.45 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2254.61 1479.7 L2259.49 1479.7 L2259.49 1485.58 L2254.61 1485.58 L2254.61 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M2280.26 1466.44 Q2277.11 1466.44 2275.26 1468.59 Q2273.43 1470.74 2273.43 1474.49 Q2273.43 1478.22 2275.26 1480.39 Q2277.11 1482.55 2280.26 1482.55 Q2283.41 1482.55 2285.23 1480.39 Q2287.09 1478.22 2287.09 1474.49 Q2287.09 1470.74 2285.23 1468.59 Q2283.41 1466.44 2280.26 1466.44 M2289.54 1451.78 L2289.54 1456.04 Q2287.78 1455.21 2285.98 1454.77 Q2284.19 1454.33 2282.43 1454.33 Q2277.8 1454.33 2275.35 1457.45 Q2272.92 1460.58 2272.57 1466.9 Q2273.94 1464.89 2276 1463.82 Q2278.06 1462.73 2280.54 1462.73 Q2285.74 1462.73 2288.75 1465.9 Q2291.79 1469.05 2291.79 1474.49 Q2291.79 1479.82 2288.64 1483.03 Q2285.49 1486.25 2280.26 1486.25 Q2274.26 1486.25 2271.09 1481.67 Q2267.92 1477.06 2267.92 1468.33 Q2267.92 1460.14 2271.81 1455.28 Q2275.7 1450.39 2282.25 1450.39 Q2284.01 1450.39 2285.79 1450.74 Q2287.6 1451.09 2289.54 1451.78 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M983.914 1533.76 L983.914 1539.24 Q981.431 1537.87 978.917 1537.2 Q976.434 1536.5 973.888 1536.5 Q968.191 1536.5 965.04 1540.13 Q961.889 1543.73 961.889 1550.25 Q961.889 1556.78 965.04 1560.4 Q968.191 1564 973.888 1564 Q976.434 1564 978.917 1563.33 Q981.431 1562.63 983.914 1561.26 L983.914 1566.68 Q981.463 1567.82 978.821 1568.39 Q976.211 1568.97 973.251 1568.97 Q965.199 1568.97 960.456 1563.91 Q955.714 1558.85 955.714 1550.25 Q955.714 1541.53 960.488 1536.53 Q965.294 1531.54 973.633 1531.54 Q976.339 1531.54 978.917 1532.11 Q981.495 1532.65 983.914 1533.76 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1007.91 1536.5 Q1003.2 1536.5 1000.46 1540.19 Q997.728 1543.85 997.728 1550.25 Q997.728 1556.65 1000.43 1560.34 Q1003.17 1564 1007.91 1564 Q1012.59 1564 1015.33 1560.31 Q1018.07 1556.62 1018.07 1550.25 Q1018.07 1543.92 1015.33 1540.23 Q1012.59 1536.5 1007.91 1536.5 M1007.91 1531.54 Q1015.55 1531.54 1019.91 1536.5 Q1024.27 1541.47 1024.27 1550.25 Q1024.27 1559 1019.91 1564 Q1015.55 1568.97 1007.91 1568.97 Q1000.24 1568.97 995.882 1564 Q991.553 1559 991.553 1550.25 Q991.553 1541.47 995.882 1536.5 Q1000.24 1531.54 1007.91 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1061.73 1539.24 Q1063.93 1535.29 1066.99 1533.41 Q1070.04 1531.54 1074.18 1531.54 Q1079.75 1531.54 1082.77 1535.45 Q1085.8 1539.33 1085.8 1546.53 L1085.8 1568.04 L1079.91 1568.04 L1079.91 1546.72 Q1079.91 1541.59 1078.09 1539.11 Q1076.28 1536.63 1072.56 1536.63 Q1068 1536.63 1065.36 1539.65 Q1062.72 1542.68 1062.72 1547.9 L1062.72 1568.04 L1056.83 1568.04 L1056.83 1546.72 Q1056.83 1541.56 1055.02 1539.11 Q1053.2 1536.63 1049.42 1536.63 Q1044.93 1536.63 1042.29 1539.68 Q1039.65 1542.71 1039.65 1547.9 L1039.65 1568.04 L1033.76 1568.04 L1033.76 1532.4 L1039.65 1532.4 L1039.65 1537.93 Q1041.65 1534.66 1044.45 1533.1 Q1047.25 1531.54 1051.1 1531.54 Q1054.99 1531.54 1057.69 1533.51 Q1060.43 1535.48 1061.73 1539.24 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1103.14 1562.7 L1103.14 1581.6 L1097.26 1581.6 L1097.26 1532.4 L1103.14 1532.4 L1103.14 1537.81 Q1104.99 1534.62 1107.79 1533.1 Q1110.62 1531.54 1114.54 1531.54 Q1121.03 1531.54 1125.07 1536.69 Q1129.15 1541.85 1129.15 1550.25 Q1129.15 1558.65 1125.07 1563.81 Q1121.03 1568.97 1114.54 1568.97 Q1110.62 1568.97 1107.79 1567.44 Q1104.99 1565.88 1103.14 1562.7 M1123.07 1550.25 Q1123.07 1543.79 1120.39 1540.13 Q1117.75 1536.44 1113.11 1536.44 Q1108.46 1536.44 1105.79 1540.13 Q1103.14 1543.79 1103.14 1550.25 Q1103.14 1556.71 1105.79 1560.4 Q1108.46 1564.07 1113.11 1564.07 Q1117.75 1564.07 1120.39 1560.4 Q1123.07 1556.71 1123.07 1550.25 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1138.25 1553.98 L1138.25 1532.4 L1144.11 1532.4 L1144.11 1553.75 Q1144.11 1558.81 1146.08 1561.36 Q1148.05 1563.87 1152 1563.87 Q1156.74 1563.87 1159.48 1560.85 Q1162.25 1557.83 1162.25 1552.61 L1162.25 1532.4 L1168.11 1532.4 L1168.11 1568.04 L1162.25 1568.04 L1162.25 1562.57 Q1160.12 1565.82 1157.28 1567.41 Q1154.48 1568.97 1150.76 1568.97 Q1144.62 1568.97 1141.43 1565.15 Q1138.25 1561.33 1138.25 1553.98 M1152.99 1531.54 L1152.99 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1185.96 1522.27 L1185.96 1532.4 L1198.02 1532.4 L1198.02 1536.95 L1185.96 1536.95 L1185.96 1556.3 Q1185.96 1560.66 1187.14 1561.9 Q1188.35 1563.14 1192.01 1563.14 L1198.02 1563.14 L1198.02 1568.04 L1192.01 1568.04 Q1185.23 1568.04 1182.65 1565.53 Q1180.07 1562.98 1180.07 1556.3 L1180.07 1536.95 L1175.78 1536.95 L1175.78 1532.4 L1180.07 1532.4 L1180.07 1522.27 L1185.96 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1221.93 1550.12 Q1214.83 1550.12 1212.09 1551.75 Q1209.36 1553.37 1209.36 1557.29 Q1209.36 1560.4 1211.39 1562.25 Q1213.46 1564.07 1216.99 1564.07 Q1221.86 1564.07 1224.79 1560.63 Q1227.75 1557.16 1227.75 1551.43 L1227.75 1550.12 L1221.93 1550.12 M1233.61 1547.71 L1233.61 1568.04 L1227.75 1568.04 L1227.75 1562.63 Q1225.75 1565.88 1222.76 1567.44 Q1219.76 1568.97 1215.43 1568.97 Q1209.96 1568.97 1206.71 1565.91 Q1203.5 1562.82 1203.5 1557.67 Q1203.5 1551.65 1207.51 1548.6 Q1211.55 1545.54 1219.54 1545.54 L1227.75 1545.54 L1227.75 1544.97 Q1227.75 1540.93 1225.08 1538.73 Q1222.44 1536.5 1217.63 1536.5 Q1214.58 1536.5 1211.68 1537.23 Q1208.78 1537.97 1206.11 1539.43 L1206.11 1534.02 Q1209.32 1532.78 1212.35 1532.17 Q1215.37 1531.54 1218.24 1531.54 Q1225.97 1531.54 1229.79 1535.55 Q1233.61 1539.56 1233.61 1547.71 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1251.46 1522.27 L1251.46 1532.4 L1263.53 1532.4 L1263.53 1536.95 L1251.46 1536.95 L1251.46 1556.3 Q1251.46 1560.66 1252.64 1561.9 Q1253.85 1563.14 1257.51 1563.14 L1263.53 1563.14 L1263.53 1568.04 L1257.51 1568.04 Q1250.73 1568.04 1248.15 1565.53 Q1245.58 1562.98 1245.58 1556.3 L1245.58 1536.95 L1241.28 1536.95 L1241.28 1532.4 L1245.58 1532.4 L1245.58 1522.27 L1251.46 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1271.23 1532.4 L1277.09 1532.4 L1277.09 1568.04 L1271.23 1568.04 L1271.23 1532.4 M1271.23 1518.52 L1277.09 1518.52 L1277.09 1525.93 L1271.23 1525.93 L1271.23 1518.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1303.15 1536.5 Q1298.44 1536.5 1295.71 1540.19 Q1292.97 1543.85 1292.97 1550.25 Q1292.97 1556.65 1295.67 1560.34 Q1298.41 1564 1303.15 1564 Q1307.83 1564 1310.57 1560.31 Q1313.31 1556.62 1313.31 1550.25 Q1313.31 1543.92 1310.57 1540.23 Q1307.83 1536.5 1303.15 1536.5 M1303.15 1531.54 Q1310.79 1531.54 1315.15 1536.5 Q1319.51 1541.47 1319.51 1550.25 Q1319.51 1559 1315.15 1564 Q1310.79 1568.97 1303.15 1568.97 Q1295.48 1568.97 1291.12 1564 Q1286.79 1559 1286.79 1550.25 Q1286.79 1541.47 1291.12 1536.5 Q1295.48 1531.54 1303.15 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1358.85 1546.53 L1358.85 1568.04 L1353 1568.04 L1353 1546.72 Q1353 1541.66 1351.02 1539.14 Q1349.05 1536.63 1345.1 1536.63 Q1340.36 1536.63 1337.62 1539.65 Q1334.89 1542.68 1334.89 1547.9 L1334.89 1568.04 L1329 1568.04 L1329 1532.4 L1334.89 1532.4 L1334.89 1537.93 Q1336.99 1534.72 1339.82 1533.13 Q1342.69 1531.54 1346.41 1531.54 Q1352.55 1531.54 1355.7 1535.36 Q1358.85 1539.14 1358.85 1546.53 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1397.05 1522.27 L1397.05 1532.4 L1409.11 1532.4 L1409.11 1536.95 L1397.05 1536.95 L1397.05 1556.3 Q1397.05 1560.66 1398.23 1561.9 Q1399.44 1563.14 1403.1 1563.14 L1409.11 1563.14 L1409.11 1568.04 L1403.1 1568.04 Q1396.32 1568.04 1393.74 1565.53 Q1391.16 1562.98 1391.16 1556.3 L1391.16 1536.95 L1386.86 1536.95 L1386.86 1532.4 L1391.16 1532.4 L1391.16 1522.27 L1397.05 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1416.81 1532.4 L1422.67 1532.4 L1422.67 1568.04 L1416.81 1568.04 L1416.81 1532.4 M1416.81 1518.52 L1422.67 1518.52 L1422.67 1525.93 L1416.81 1525.93 L1416.81 1518.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1462.68 1539.24 Q1464.87 1535.29 1467.93 1533.41 Q1470.99 1531.54 1475.12 1531.54 Q1480.69 1531.54 1483.72 1535.45 Q1486.74 1539.33 1486.74 1546.53 L1486.74 1568.04 L1480.85 1568.04 L1480.85 1546.72 Q1480.85 1541.59 1479.04 1539.11 Q1477.22 1536.63 1473.5 1536.63 Q1468.95 1536.63 1466.31 1539.65 Q1463.67 1542.68 1463.67 1547.9 L1463.67 1568.04 L1457.78 1568.04 L1457.78 1546.72 Q1457.78 1541.56 1455.96 1539.11 Q1454.15 1536.63 1450.36 1536.63 Q1445.87 1536.63 1443.23 1539.68 Q1440.59 1542.71 1440.59 1547.9 L1440.59 1568.04 L1434.7 1568.04 L1434.7 1532.4 L1440.59 1532.4 L1440.59 1537.93 Q1442.59 1534.66 1445.4 1533.1 Q1448.2 1531.54 1452.05 1531.54 Q1455.93 1531.54 1458.64 1533.51 Q1461.37 1535.48 1462.68 1539.24 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1528.91 1548.76 L1528.91 1551.62 L1501.99 1551.62 Q1502.37 1557.67 1505.62 1560.85 Q1508.89 1564 1514.72 1564 Q1518.09 1564 1521.24 1563.17 Q1524.43 1562.35 1527.55 1560.69 L1527.55 1566.23 Q1524.39 1567.57 1521.08 1568.27 Q1517.77 1568.97 1514.37 1568.97 Q1505.84 1568.97 1500.84 1564 Q1495.88 1559.04 1495.88 1550.57 Q1495.88 1541.82 1500.59 1536.69 Q1505.33 1531.54 1513.35 1531.54 Q1520.54 1531.54 1524.71 1536.18 Q1528.91 1540.8 1528.91 1548.76 M1523.06 1547.04 Q1522.99 1542.23 1520.35 1539.37 Q1517.74 1536.5 1513.41 1536.5 Q1508.51 1536.5 1505.55 1539.27 Q1502.62 1542.04 1502.18 1547.07 L1523.06 1547.04 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1573.31 1518.58 Q1569.05 1525.9 1566.98 1533.06 Q1564.91 1540.23 1564.91 1547.58 Q1564.91 1554.93 1566.98 1562.16 Q1569.08 1569.35 1573.31 1576.64 L1568.22 1576.64 Q1563.45 1569.16 1561.06 1561.93 Q1558.71 1554.71 1558.71 1547.58 Q1558.71 1540.48 1561.06 1533.29 Q1563.42 1526.09 1568.22 1518.58 L1573.31 1518.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1607.4 1533.45 L1607.4 1538.98 Q1604.92 1537.71 1602.25 1537.07 Q1599.57 1536.44 1596.71 1536.44 Q1592.35 1536.44 1590.15 1537.77 Q1587.99 1539.11 1587.99 1541.79 Q1587.99 1543.82 1589.55 1545 Q1591.11 1546.15 1595.82 1547.2 L1597.82 1547.64 Q1604.06 1548.98 1606.67 1551.43 Q1609.31 1553.85 1609.31 1558.21 Q1609.31 1563.17 1605.37 1566.07 Q1601.45 1568.97 1594.58 1568.97 Q1591.71 1568.97 1588.59 1568.39 Q1585.51 1567.85 1582.07 1566.74 L1582.07 1560.69 Q1585.31 1562.38 1588.47 1563.24 Q1591.62 1564.07 1594.7 1564.07 Q1598.84 1564.07 1601.07 1562.66 Q1603.3 1561.23 1603.3 1558.65 Q1603.3 1556.27 1601.67 1554.99 Q1600.08 1553.72 1594.64 1552.54 L1592.6 1552.07 Q1587.16 1550.92 1584.74 1548.56 Q1582.32 1546.18 1582.32 1542.04 Q1582.32 1537.01 1585.89 1534.27 Q1589.45 1531.54 1596.01 1531.54 Q1599.26 1531.54 1602.12 1532.01 Q1604.98 1532.49 1607.4 1533.45 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1617.72 1518.58 L1622.81 1518.58 Q1627.58 1526.09 1629.94 1533.29 Q1632.32 1540.48 1632.32 1547.58 Q1632.32 1554.71 1629.94 1561.93 Q1627.58 1569.16 1622.81 1576.64 L1617.72 1576.64 Q1621.95 1569.35 1624.02 1562.16 Q1626.12 1554.93 1626.12 1547.58 Q1626.12 1540.23 1624.02 1533.06 Q1621.95 1525.9 1617.72 1518.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,1386.08 2352.76,1386.08 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,1122.52 2352.76,1122.52 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,858.96 2352.76,858.96 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,595.4 2352.76,595.4 \"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,331.839 2352.76,331.839 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1423.18 235.283,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1386.08 254.18,1386.08 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1122.52 254.18,1122.52 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,858.96 254.18,858.96 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,595.4 254.18,595.4 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,331.839 254.18,331.839 \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M187.338 1371.88 Q183.727 1371.88 181.899 1375.45 Q180.093 1378.99 180.093 1386.12 Q180.093 1393.22 181.899 1396.79 Q183.727 1400.33 187.338 1400.33 Q190.973 1400.33 192.778 1396.79 Q194.607 1393.22 194.607 1386.12 Q194.607 1378.99 192.778 1375.45 Q190.973 1371.88 187.338 1371.88 M187.338 1368.18 Q193.149 1368.18 196.204 1372.78 Q199.283 1377.37 199.283 1386.12 Q199.283 1394.84 196.204 1399.45 Q193.149 1404.03 187.338 1404.03 Q181.528 1404.03 178.45 1399.45 Q175.394 1394.84 175.394 1386.12 Q175.394 1377.37 178.45 1372.78 Q181.528 1368.18 187.338 1368.18 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M117.825 1135.87 L125.464 1135.87 L125.464 1109.5 L117.154 1111.17 L117.154 1106.91 L125.418 1105.24 L130.093 1105.24 L130.093 1135.87 L137.732 1135.87 L137.732 1139.8 L117.825 1139.8 L117.825 1135.87 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M157.177 1108.32 Q153.566 1108.32 151.737 1111.88 Q149.931 1115.43 149.931 1122.56 Q149.931 1129.66 151.737 1133.23 Q153.566 1136.77 157.177 1136.77 Q160.811 1136.77 162.616 1133.23 Q164.445 1129.66 164.445 1122.56 Q164.445 1115.43 162.616 1111.88 Q160.811 1108.32 157.177 1108.32 M157.177 1104.62 Q162.987 1104.62 166.042 1109.22 Q169.121 1113.81 169.121 1122.56 Q169.121 1131.28 166.042 1135.89 Q162.987 1140.47 157.177 1140.47 Q151.366 1140.47 148.288 1135.89 Q145.232 1131.28 145.232 1122.56 Q145.232 1113.81 148.288 1109.22 Q151.366 1104.62 157.177 1104.62 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M187.338 1108.32 Q183.727 1108.32 181.899 1111.88 Q180.093 1115.43 180.093 1122.56 Q180.093 1129.66 181.899 1133.23 Q183.727 1136.77 187.338 1136.77 Q190.973 1136.77 192.778 1133.23 Q194.607 1129.66 194.607 1122.56 Q194.607 1115.43 192.778 1111.88 Q190.973 1108.32 187.338 1108.32 M187.338 1104.62 Q193.149 1104.62 196.204 1109.22 Q199.283 1113.81 199.283 1122.56 Q199.283 1131.28 196.204 1135.89 Q193.149 1140.47 187.338 1140.47 Q181.528 1140.47 178.45 1135.89 Q175.394 1131.28 175.394 1122.56 Q175.394 1113.81 178.45 1109.22 Q181.528 1104.62 187.338 1104.62 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M121.043 872.305 L137.362 872.305 L137.362 876.24 L115.418 876.24 L115.418 872.305 Q118.08 869.551 122.663 864.921 Q127.269 860.268 128.45 858.926 Q130.695 856.402 131.575 854.666 Q132.478 852.907 132.478 851.217 Q132.478 848.463 130.533 846.727 Q128.612 844.99 125.51 844.99 Q123.311 844.99 120.857 845.754 Q118.427 846.518 115.649 848.069 L115.649 843.347 Q118.473 842.213 120.927 841.634 Q123.38 841.055 125.418 841.055 Q130.788 841.055 133.982 843.74 Q137.177 846.426 137.177 850.916 Q137.177 853.046 136.367 854.967 Q135.579 856.865 133.473 859.458 Q132.894 860.129 129.792 863.347 Q126.691 866.541 121.043 872.305 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M157.177 844.759 Q153.566 844.759 151.737 848.324 Q149.931 851.865 149.931 858.995 Q149.931 866.101 151.737 869.666 Q153.566 873.208 157.177 873.208 Q160.811 873.208 162.616 869.666 Q164.445 866.101 164.445 858.995 Q164.445 851.865 162.616 848.324 Q160.811 844.759 157.177 844.759 M157.177 841.055 Q162.987 841.055 166.042 845.662 Q169.121 850.245 169.121 858.995 Q169.121 867.722 166.042 872.328 Q162.987 876.912 157.177 876.912 Q151.366 876.912 148.288 872.328 Q145.232 867.722 145.232 858.995 Q145.232 850.245 148.288 845.662 Q151.366 841.055 157.177 841.055 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M187.338 844.759 Q183.727 844.759 181.899 848.324 Q180.093 851.865 180.093 858.995 Q180.093 866.101 181.899 869.666 Q183.727 873.208 187.338 873.208 Q190.973 873.208 192.778 869.666 Q194.607 866.101 194.607 858.995 Q194.607 851.865 192.778 848.324 Q190.973 844.759 187.338 844.759 M187.338 841.055 Q193.149 841.055 196.204 845.662 Q199.283 850.245 199.283 858.995 Q199.283 867.722 196.204 872.328 Q193.149 876.912 187.338 876.912 Q181.528 876.912 178.45 872.328 Q175.394 867.722 175.394 858.995 Q175.394 850.245 178.45 845.662 Q181.528 841.055 187.338 841.055 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M131.181 594.046 Q134.538 594.763 136.413 597.032 Q138.311 599.3 138.311 602.633 Q138.311 607.749 134.792 610.55 Q131.274 613.351 124.793 613.351 Q122.617 613.351 120.302 612.911 Q118.01 612.494 115.556 611.638 L115.556 607.124 Q117.501 608.258 119.816 608.837 Q122.13 609.416 124.654 609.416 Q129.052 609.416 131.343 607.68 Q133.658 605.944 133.658 602.633 Q133.658 599.578 131.505 597.865 Q129.376 596.129 125.556 596.129 L121.529 596.129 L121.529 592.286 L125.742 592.286 Q129.191 592.286 131.019 590.921 Q132.848 589.532 132.848 586.939 Q132.848 584.277 130.95 582.865 Q129.075 581.43 125.556 581.43 Q123.635 581.43 121.436 581.847 Q119.237 582.263 116.598 583.143 L116.598 578.976 Q119.26 578.235 121.575 577.865 Q123.913 577.495 125.973 577.495 Q131.297 577.495 134.399 579.925 Q137.501 582.333 137.501 586.453 Q137.501 589.323 135.857 591.314 Q134.214 593.282 131.181 594.046 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M157.177 581.198 Q153.566 581.198 151.737 584.763 Q149.931 588.305 149.931 595.434 Q149.931 602.541 151.737 606.106 Q153.566 609.647 157.177 609.647 Q160.811 609.647 162.616 606.106 Q164.445 602.541 164.445 595.434 Q164.445 588.305 162.616 584.763 Q160.811 581.198 157.177 581.198 M157.177 577.495 Q162.987 577.495 166.042 582.101 Q169.121 586.684 169.121 595.434 Q169.121 604.161 166.042 608.768 Q162.987 613.351 157.177 613.351 Q151.366 613.351 148.288 608.768 Q145.232 604.161 145.232 595.434 Q145.232 586.684 148.288 582.101 Q151.366 577.495 157.177 577.495 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M187.338 581.198 Q183.727 581.198 181.899 584.763 Q180.093 588.305 180.093 595.434 Q180.093 602.541 181.899 606.106 Q183.727 609.647 187.338 609.647 Q190.973 609.647 192.778 606.106 Q194.607 602.541 194.607 595.434 Q194.607 588.305 192.778 584.763 Q190.973 581.198 187.338 581.198 M187.338 577.495 Q193.149 577.495 196.204 582.101 Q199.283 586.684 199.283 595.434 Q199.283 604.161 196.204 608.768 Q193.149 613.351 187.338 613.351 Q181.528 613.351 178.45 608.768 Q175.394 604.161 175.394 595.434 Q175.394 586.684 178.45 582.101 Q181.528 577.495 187.338 577.495 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M129.862 318.633 L118.056 337.082 L129.862 337.082 L129.862 318.633 M128.635 314.559 L134.515 314.559 L134.515 337.082 L139.445 337.082 L139.445 340.971 L134.515 340.971 L134.515 349.119 L129.862 349.119 L129.862 340.971 L114.26 340.971 L114.26 336.457 L128.635 314.559 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M157.177 317.638 Q153.566 317.638 151.737 321.203 Q149.931 324.744 149.931 331.874 Q149.931 338.98 151.737 342.545 Q153.566 346.087 157.177 346.087 Q160.811 346.087 162.616 342.545 Q164.445 338.98 164.445 331.874 Q164.445 324.744 162.616 321.203 Q160.811 317.638 157.177 317.638 M157.177 313.934 Q162.987 313.934 166.042 318.54 Q169.121 323.124 169.121 331.874 Q169.121 340.601 166.042 345.207 Q162.987 349.79 157.177 349.79 Q151.366 349.79 148.288 345.207 Q145.232 340.601 145.232 331.874 Q145.232 323.124 148.288 318.54 Q151.366 313.934 157.177 313.934 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M187.338 317.638 Q183.727 317.638 181.899 321.203 Q180.093 324.744 180.093 331.874 Q180.093 338.98 181.899 342.545 Q183.727 346.087 187.338 346.087 Q190.973 346.087 192.778 342.545 Q194.607 338.98 194.607 331.874 Q194.607 324.744 192.778 321.203 Q190.973 317.638 187.338 317.638 M187.338 313.934 Q193.149 313.934 196.204 318.54 Q199.283 323.124 199.283 331.874 Q199.283 340.601 196.204 345.207 Q193.149 349.79 187.338 349.79 Q181.528 349.79 178.45 345.207 Q175.394 340.601 175.394 331.874 Q175.394 323.124 178.45 318.54 Q181.528 313.934 187.338 313.934 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M35.1993 955.099 Q31.2526 952.903 29.3747 949.847 Q27.4968 946.791 27.4968 942.654 Q27.4968 937.084 31.4117 934.06 Q35.2948 931.036 42.4881 931.036 L64.0042 931.036 L64.0042 936.925 L42.679 936.925 Q37.5546 936.925 35.072 938.739 Q32.5894 940.553 32.5894 944.277 Q32.5894 948.829 35.6131 951.47 Q38.6368 954.112 43.8567 954.112 L64.0042 954.112 L64.0042 960 L42.679 960 Q37.5228 960 35.072 961.815 Q32.5894 963.629 32.5894 967.416 Q32.5894 971.904 35.6449 974.546 Q38.6686 977.188 43.8567 977.188 L64.0042 977.188 L64.0042 983.076 L28.3562 983.076 L28.3562 977.188 L33.8944 977.188 Q30.616 975.183 29.0564 972.382 Q27.4968 969.581 27.4968 965.729 Q27.4968 961.846 29.4702 959.141 Q31.4436 956.404 35.1993 955.099 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M44.7161 888.864 L47.5806 888.864 L47.5806 915.79 Q53.6281 915.409 56.8109 912.162 Q59.9619 908.884 59.9619 903.059 Q59.9619 899.685 59.1344 896.534 Q58.3069 893.351 56.6518 890.232 L62.1899 890.232 Q63.5267 893.383 64.227 896.693 Q64.9272 900.004 64.9272 903.409 Q64.9272 911.939 59.9619 916.936 Q54.9967 921.902 46.5303 921.902 Q37.7774 921.902 32.6531 917.191 Q27.4968 912.449 27.4968 904.428 Q27.4968 897.234 32.1438 893.065 Q36.7589 888.864 44.7161 888.864 M42.9973 894.72 Q38.1912 894.784 35.3266 897.425 Q32.4621 900.035 32.4621 904.364 Q32.4621 909.266 35.2312 912.226 Q38.0002 915.154 43.0292 915.6 L42.9973 894.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M46.0847 863.051 Q46.0847 870.148 47.7079 872.886 Q49.3312 875.623 53.2461 875.623 Q56.3653 875.623 58.2114 873.586 Q60.0256 871.517 60.0256 867.984 Q60.0256 863.114 56.5881 860.186 Q53.1188 857.226 47.3897 857.226 L46.0847 857.226 L46.0847 863.051 M43.6657 851.37 L64.0042 851.37 L64.0042 857.226 L58.5933 857.226 Q61.8398 859.231 63.3994 862.223 Q64.9272 865.215 64.9272 869.544 Q64.9272 875.018 61.8716 878.265 Q58.7843 881.479 53.6281 881.479 Q47.6125 881.479 44.5569 877.469 Q41.5014 873.427 41.5014 865.438 L41.5014 857.226 L40.9285 857.226 Q36.8862 857.226 34.6901 859.9 Q32.4621 862.541 32.4621 867.347 Q32.4621 870.403 33.1941 873.299 Q33.9262 876.196 35.3903 878.869 L29.9795 878.869 Q28.7381 875.655 28.1334 872.631 Q27.4968 869.607 27.4968 866.743 Q27.4968 859.008 31.5072 855.189 Q35.5176 851.37 43.6657 851.37 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M42.4881 809.674 L64.0042 809.674 L64.0042 815.531 L42.679 815.531 Q37.6183 815.531 35.1038 817.504 Q32.5894 819.477 32.5894 823.424 Q32.5894 828.167 35.6131 830.904 Q38.6368 833.641 43.8567 833.641 L64.0042 833.641 L64.0042 839.529 L28.3562 839.529 L28.3562 833.641 L33.8944 833.641 Q30.6797 831.54 29.0883 828.708 Q27.4968 825.843 27.4968 822.119 Q27.4968 815.976 31.3163 812.825 Q35.1038 809.674 42.4881 809.674 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M33.8307 756.616 Q33.2578 757.603 33.0032 758.78 Q32.7167 759.926 32.7167 761.327 Q32.7167 766.292 35.9632 768.965 Q39.1779 771.607 45.2253 771.607 L64.0042 771.607 L64.0042 777.496 L28.3562 777.496 L28.3562 771.607 L33.8944 771.607 Q30.6479 769.761 29.0883 766.801 Q27.4968 763.841 27.4968 759.608 Q27.4968 759.003 27.5923 758.271 Q27.656 757.539 27.8151 756.648 L33.8307 756.616 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M44.7161 721.414 L47.5806 721.414 L47.5806 748.341 Q53.6281 747.959 56.8109 744.712 Q59.9619 741.434 59.9619 735.609 Q59.9619 732.235 59.1344 729.084 Q58.3069 725.901 56.6518 722.782 L62.1899 722.782 Q63.5267 725.933 64.227 729.243 Q64.9272 732.554 64.9272 735.959 Q64.9272 744.489 59.9619 749.486 Q54.9967 754.452 46.5303 754.452 Q37.7774 754.452 32.6531 749.741 Q27.4968 744.999 27.4968 736.978 Q27.4968 729.785 32.1438 725.615 Q36.7589 721.414 44.7161 721.414 M42.9973 727.27 Q38.1912 727.334 35.3266 729.976 Q32.4621 732.585 32.4621 736.914 Q32.4621 741.816 35.2312 744.776 Q38.0002 747.704 43.0292 748.15 L42.9973 727.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M28.3562 715.207 L28.3562 709.351 L56.1743 702.03 L28.3562 694.741 L28.3562 687.835 L56.1743 680.514 L28.3562 673.225 L28.3562 667.369 L64.0042 676.695 L64.0042 683.601 L34.7856 691.272 L64.0042 698.975 L64.0042 705.881 L28.3562 715.207 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M46.0847 642.288 Q46.0847 649.386 47.7079 652.123 Q49.3312 654.86 53.2461 654.86 Q56.3653 654.86 58.2114 652.823 Q60.0256 650.754 60.0256 647.221 Q60.0256 642.352 56.5881 639.423 Q53.1188 636.463 47.3897 636.463 L46.0847 636.463 L46.0847 642.288 M43.6657 630.607 L64.0042 630.607 L64.0042 636.463 L58.5933 636.463 Q61.8398 638.468 63.3994 641.46 Q64.9272 644.452 64.9272 648.781 Q64.9272 654.255 61.8716 657.502 Q58.7843 660.717 53.6281 660.717 Q47.6125 660.717 44.5569 656.706 Q41.5014 652.664 41.5014 644.675 L41.5014 636.463 L40.9285 636.463 Q36.8862 636.463 34.6901 639.137 Q32.4621 641.779 32.4621 646.585 Q32.4621 649.64 33.1941 652.537 Q33.9262 655.433 35.3903 658.107 L29.9795 658.107 Q28.7381 654.892 28.1334 651.868 Q27.4968 648.845 27.4968 645.98 Q27.4968 638.246 31.5072 634.426 Q35.5176 630.607 43.6657 630.607 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M33.8307 597.887 Q33.2578 598.874 33.0032 600.051 Q32.7167 601.197 32.7167 602.598 Q32.7167 607.563 35.9632 610.237 Q39.1779 612.878 45.2253 612.878 L64.0042 612.878 L64.0042 618.767 L28.3562 618.767 L28.3562 612.878 L33.8944 612.878 Q30.6479 611.032 29.0883 608.072 Q27.4968 605.112 27.4968 600.879 Q27.4968 600.274 27.5923 599.542 Q27.656 598.81 27.8151 597.919 L33.8307 597.887 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M33.7671 569.432 L14.479 569.432 L14.479 563.576 L64.0042 563.576 L64.0042 569.432 L58.657 569.432 Q61.8398 571.278 63.3994 574.111 Q64.9272 576.912 64.9272 580.859 Q64.9272 587.32 59.771 591.394 Q54.6147 595.436 46.212 595.436 Q37.8093 595.436 32.6531 591.394 Q27.4968 587.32 27.4968 580.859 Q27.4968 576.912 29.0564 574.111 Q30.5842 571.278 33.7671 569.432 M46.212 589.389 Q52.6732 589.389 56.3653 586.747 Q60.0256 584.074 60.0256 579.427 Q60.0256 574.78 56.3653 572.106 Q52.6732 569.432 46.212 569.432 Q39.7508 569.432 36.0905 572.106 Q32.3984 574.78 32.3984 579.427 Q32.3984 584.074 36.0905 586.747 Q39.7508 589.389 46.212 589.389 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M720.553 17.6457 Q711.641 17.6457 706.375 24.2892 Q701.149 30.9327 701.149 42.3968 Q701.149 53.8203 706.375 60.4638 Q711.641 67.1073 720.553 67.1073 Q729.465 67.1073 734.65 60.4638 Q739.876 53.8203 739.876 42.3968 Q739.876 30.9327 734.65 24.2892 Q729.465 17.6457 720.553 17.6457 M720.553 11.0023 Q733.273 11.0023 740.889 19.5497 Q748.504 28.0566 748.504 42.3968 Q748.504 56.6965 740.889 65.2439 Q733.273 73.7508 720.553 73.7508 Q707.793 73.7508 700.137 65.2439 Q692.521 56.737 692.521 42.3968 Q692.521 28.0566 700.137 19.5497 Q707.793 11.0023 720.553 11.0023 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M768.192 65.7705 L768.192 89.8329 L760.698 89.8329 L760.698 27.2059 L768.192 27.2059 L768.192 34.0924 Q770.541 30.0415 774.106 28.0971 Q777.711 26.1121 782.694 26.1121 Q790.958 26.1121 796.102 32.6746 Q801.288 39.2371 801.288 49.9314 Q801.288 60.6258 796.102 67.1883 Q790.958 73.7508 782.694 73.7508 Q777.711 73.7508 774.106 71.8063 Q770.541 69.8214 768.192 65.7705 M793.55 49.9314 Q793.55 41.7081 790.148 37.0496 Q786.785 32.3505 780.871 32.3505 Q774.957 32.3505 771.554 37.0496 Q768.192 41.7081 768.192 49.9314 Q768.192 58.1548 771.554 62.8538 Q774.957 67.5124 780.871 67.5124 Q786.785 67.5124 790.148 62.8538 Q793.55 58.1548 793.55 49.9314 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M821.016 14.324 L821.016 27.2059 L836.368 27.2059 L836.368 32.9987 L821.016 32.9987 L821.016 57.6282 Q821.016 63.1779 822.514 64.7578 Q824.054 66.3376 828.712 66.3376 L836.368 66.3376 L836.368 72.576 L828.712 72.576 Q820.084 72.576 816.803 69.3758 Q813.521 66.1351 813.521 57.6282 L813.521 32.9987 L808.053 32.9987 L808.053 27.2059 L813.521 27.2059 L813.521 14.324 L821.016 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M846.172 27.2059 L853.625 27.2059 L853.625 72.576 L846.172 72.576 L846.172 27.2059 M846.172 9.54393 L853.625 9.54393 L853.625 18.9825 L846.172 18.9825 L846.172 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M904.545 35.9153 Q907.34 30.8922 911.229 28.5022 Q915.118 26.1121 920.384 26.1121 Q927.473 26.1121 931.322 31.0947 Q935.17 36.0368 935.17 45.1919 L935.17 72.576 L927.676 72.576 L927.676 45.4349 Q927.676 38.913 925.367 35.7533 Q923.058 32.5936 918.318 32.5936 Q912.525 32.5936 909.163 36.4419 Q905.801 40.2903 905.801 46.9338 L905.801 72.576 L898.307 72.576 L898.307 45.4349 Q898.307 38.8725 895.998 35.7533 Q893.689 32.5936 888.868 32.5936 Q883.156 32.5936 879.794 36.4824 Q876.432 40.3308 876.432 46.9338 L876.432 72.576 L868.938 72.576 L868.938 27.2059 L876.432 27.2059 L876.432 34.2544 Q878.984 30.082 882.549 28.0971 Q886.114 26.1121 891.015 26.1121 Q895.957 26.1121 899.401 28.6237 Q902.884 31.1352 904.545 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M970.656 49.7694 Q961.622 49.7694 958.139 51.8354 Q954.655 53.9013 954.655 58.8839 Q954.655 62.8538 957.247 65.2034 Q959.881 67.5124 964.377 67.5124 Q970.575 67.5124 974.302 63.1374 Q978.069 58.7219 978.069 51.4303 L978.069 49.7694 L970.656 49.7694 M985.523 46.6907 L985.523 72.576 L978.069 72.576 L978.069 65.6895 Q975.517 69.8214 971.709 71.8063 Q967.901 73.7508 962.392 73.7508 Q955.425 73.7508 951.293 69.8619 Q947.201 65.9325 947.201 59.3701 Q947.201 51.7138 952.305 47.825 Q957.45 43.9361 967.618 43.9361 L978.069 43.9361 L978.069 43.2069 Q978.069 38.0623 974.666 35.2672 Q971.304 32.4315 965.187 32.4315 Q961.298 32.4315 957.612 33.3632 Q953.926 34.295 950.523 36.1584 L950.523 29.2718 Q954.614 27.692 958.463 26.9223 Q962.311 26.1121 965.957 26.1121 Q975.801 26.1121 980.662 31.2163 Q985.523 36.3204 985.523 46.6907 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1000.88 9.54393 L1008.33 9.54393 L1008.33 72.576 L1000.88 72.576 L1000.88 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1023.93 27.2059 L1031.38 27.2059 L1031.38 72.576 L1023.93 72.576 L1023.93 27.2059 M1023.93 9.54393 L1031.38 9.54393 L1031.38 18.9825 L1023.93 18.9825 L1023.93 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1054.35 14.324 L1054.35 27.2059 L1069.7 27.2059 L1069.7 32.9987 L1054.35 32.9987 L1054.35 57.6282 Q1054.35 63.1779 1055.85 64.7578 Q1057.39 66.3376 1062.04 66.3376 L1069.7 66.3376 L1069.7 72.576 L1062.04 72.576 Q1053.42 72.576 1050.13 69.3758 Q1046.85 66.1351 1046.85 57.6282 L1046.85 32.9987 L1041.38 32.9987 L1041.38 27.2059 L1046.85 27.2059 L1046.85 14.324 L1054.35 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1098.38 76.7889 Q1095.22 84.8907 1092.22 87.3618 Q1089.23 89.8329 1084.2 89.8329 L1078.25 89.8329 L1078.25 83.5945 L1082.62 83.5945 Q1085.7 83.5945 1087.4 82.1361 Q1089.1 80.6778 1091.17 75.2496 L1092.51 71.8468 L1074.16 27.2059 L1082.06 27.2059 L1096.23 62.6918 L1110.41 27.2059 L1118.31 27.2059 L1098.38 76.7889 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1149.62 27.2059 L1157.52 27.2059 L1171.7 65.2844 L1185.88 27.2059 L1193.78 27.2059 L1176.77 72.576 L1166.64 72.576 L1149.62 27.2059 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1232.99 28.5427 L1232.99 35.5912 Q1229.83 33.9709 1226.43 33.1607 Q1223.03 32.3505 1219.38 32.3505 Q1213.83 32.3505 1211.04 34.0519 Q1208.28 35.7533 1208.28 39.156 Q1208.28 41.7486 1210.27 43.2475 Q1212.25 44.7058 1218.25 46.0426 L1220.8 46.6097 Q1228.74 48.3111 1232.06 51.4303 Q1235.42 54.509 1235.42 60.0587 Q1235.42 66.3781 1230.4 70.0644 Q1225.42 73.7508 1216.67 73.7508 Q1213.02 73.7508 1209.05 73.0216 Q1205.12 72.3329 1200.75 70.9151 L1200.75 63.2184 Q1204.88 65.3654 1208.89 66.4591 Q1212.9 67.5124 1216.83 67.5124 Q1222.1 67.5124 1224.93 65.73 Q1227.77 63.9071 1227.77 60.6258 Q1227.77 57.5877 1225.7 55.9673 Q1223.68 54.3469 1216.75 52.8481 L1214.16 52.2405 Q1207.23 50.7821 1204.15 47.7845 Q1201.07 44.7463 1201.07 39.4801 Q1201.07 33.0797 1205.61 29.5959 Q1210.15 26.1121 1218.49 26.1121 Q1222.62 26.1121 1226.27 26.7198 Q1229.91 27.3274 1232.99 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1248.35 62.2867 L1256.89 62.2867 L1256.89 72.576 L1248.35 72.576 L1248.35 62.2867 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1345.65 16.7545 L1345.65 25.383 Q1341.52 21.5346 1336.82 19.6307 Q1332.16 17.7268 1326.89 17.7268 Q1316.52 17.7268 1311.01 24.0867 Q1305.5 30.4061 1305.5 42.3968 Q1305.5 54.3469 1311.01 60.7069 Q1316.52 67.0263 1326.89 67.0263 Q1332.16 67.0263 1336.82 65.1223 Q1341.52 63.2184 1345.65 59.3701 L1345.65 67.9175 Q1341.35 70.8341 1336.53 72.2924 Q1331.75 73.7508 1326.41 73.7508 Q1312.67 73.7508 1304.77 65.3654 Q1296.88 56.9395 1296.88 42.3968 Q1296.88 27.8135 1304.77 19.4281 Q1312.67 11.0023 1326.41 11.0023 Q1331.83 11.0023 1336.61 12.4606 Q1341.44 13.8784 1345.65 16.7545 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1375.54 32.4315 Q1369.55 32.4315 1366.06 37.1306 Q1362.58 41.7891 1362.58 49.9314 Q1362.58 58.0738 1366.02 62.7728 Q1369.51 67.4314 1375.54 67.4314 Q1381.5 67.4314 1384.98 62.7323 Q1388.47 58.0333 1388.47 49.9314 Q1388.47 41.8701 1384.98 37.1711 Q1381.5 32.4315 1375.54 32.4315 M1375.54 26.1121 Q1385.27 26.1121 1390.82 32.4315 Q1396.37 38.7509 1396.37 49.9314 Q1396.37 61.0714 1390.82 67.4314 Q1385.27 73.7508 1375.54 73.7508 Q1365.78 73.7508 1360.23 67.4314 Q1354.72 61.0714 1354.72 49.9314 Q1354.72 38.7509 1360.23 32.4315 Q1365.78 26.1121 1375.54 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1444.04 35.9153 Q1446.84 30.8922 1450.73 28.5022 Q1454.62 26.1121 1459.88 26.1121 Q1466.97 26.1121 1470.82 31.0947 Q1474.67 36.0368 1474.67 45.1919 L1474.67 72.576 L1467.18 72.576 L1467.18 45.4349 Q1467.18 38.913 1464.87 35.7533 Q1462.56 32.5936 1457.82 32.5936 Q1452.02 32.5936 1448.66 36.4419 Q1445.3 40.2903 1445.3 46.9338 L1445.3 72.576 L1437.81 72.576 L1437.81 45.4349 Q1437.81 38.8725 1435.5 35.7533 Q1433.19 32.5936 1428.37 32.5936 Q1422.66 32.5936 1419.29 36.4824 Q1415.93 40.3308 1415.93 46.9338 L1415.93 72.576 L1408.44 72.576 L1408.44 27.2059 L1415.93 27.2059 L1415.93 34.2544 Q1418.48 30.082 1422.05 28.0971 Q1425.61 26.1121 1430.51 26.1121 Q1435.46 26.1121 1438.9 28.6237 Q1442.38 31.1352 1444.04 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1496.75 65.7705 L1496.75 89.8329 L1489.25 89.8329 L1489.25 27.2059 L1496.75 27.2059 L1496.75 34.0924 Q1499.1 30.0415 1502.66 28.0971 Q1506.27 26.1121 1511.25 26.1121 Q1519.51 26.1121 1524.66 32.6746 Q1529.84 39.2371 1529.84 49.9314 Q1529.84 60.6258 1524.66 67.1883 Q1519.51 73.7508 1511.25 73.7508 Q1506.27 73.7508 1502.66 71.8063 Q1499.1 69.8214 1496.75 65.7705 M1522.11 49.9314 Q1522.11 41.7081 1518.7 37.0496 Q1515.34 32.3505 1509.43 32.3505 Q1503.51 32.3505 1500.11 37.0496 Q1496.75 41.7081 1496.75 49.9314 Q1496.75 58.1548 1500.11 62.8538 Q1503.51 67.5124 1509.43 67.5124 Q1515.34 67.5124 1518.7 62.8538 Q1522.11 58.1548 1522.11 49.9314 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1541.43 54.671 L1541.43 27.2059 L1548.88 27.2059 L1548.88 54.3874 Q1548.88 60.8284 1551.39 64.0691 Q1553.91 67.2693 1558.93 67.2693 Q1564.96 67.2693 1568.45 63.421 Q1571.97 59.5726 1571.97 52.9291 L1571.97 27.2059 L1579.43 27.2059 L1579.43 72.576 L1571.97 72.576 L1571.97 65.6084 Q1569.26 69.7404 1565.65 71.7658 Q1562.09 73.7508 1557.35 73.7508 Q1549.53 73.7508 1545.48 68.8897 Q1541.43 64.0286 1541.43 54.671 M1560.18 26.1121 L1560.18 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1602.15 14.324 L1602.15 27.2059 L1617.5 27.2059 L1617.5 32.9987 L1602.15 32.9987 L1602.15 57.6282 Q1602.15 63.1779 1603.65 64.7578 Q1605.19 66.3376 1609.85 66.3376 L1617.5 66.3376 L1617.5 72.576 L1609.85 72.576 Q1601.22 72.576 1597.94 69.3758 Q1594.66 66.1351 1594.66 57.6282 L1594.66 32.9987 L1589.19 32.9987 L1589.19 27.2059 L1594.66 27.2059 L1594.66 14.324 L1602.15 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1666.12 48.0275 L1666.12 51.6733 L1631.84 51.6733 Q1632.33 59.3701 1636.46 63.421 Q1640.63 67.4314 1648.05 67.4314 Q1652.34 67.4314 1656.35 66.3781 Q1660.4 65.3249 1664.37 63.2184 L1664.37 70.267 Q1660.36 71.9684 1656.15 72.8596 Q1651.94 73.7508 1647.6 73.7508 Q1636.75 73.7508 1630.39 67.4314 Q1624.07 61.1119 1624.07 50.3365 Q1624.07 39.1965 1630.06 32.6746 Q1636.1 26.1121 1646.31 26.1121 Q1655.46 26.1121 1660.77 32.0264 Q1666.12 37.9003 1666.12 48.0275 M1658.66 45.84 Q1658.58 39.7232 1655.22 36.0774 Q1651.9 32.4315 1646.39 32.4315 Q1640.15 32.4315 1636.38 35.9558 Q1632.65 39.4801 1632.09 45.8805 L1658.66 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1696.66 12.096 L1747.82 12.096 L1747.82 18.9825 L1726.35 18.9825 L1726.35 72.576 L1718.13 72.576 L1718.13 18.9825 L1696.66 18.9825 L1696.66 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1752.85 27.2059 L1760.3 27.2059 L1760.3 72.576 L1752.85 72.576 L1752.85 27.2059 M1752.85 9.54393 L1760.3 9.54393 L1760.3 18.9825 L1752.85 18.9825 L1752.85 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1811.22 35.9153 Q1814.01 30.8922 1817.9 28.5022 Q1821.79 26.1121 1827.06 26.1121 Q1834.15 26.1121 1838 31.0947 Q1841.84 36.0368 1841.84 45.1919 L1841.84 72.576 L1834.35 72.576 L1834.35 45.4349 Q1834.35 38.913 1832.04 35.7533 Q1829.73 32.5936 1824.99 32.5936 Q1819.2 32.5936 1815.84 36.4419 Q1812.47 40.2903 1812.47 46.9338 L1812.47 72.576 L1804.98 72.576 L1804.98 45.4349 Q1804.98 38.8725 1802.67 35.7533 Q1800.36 32.5936 1795.54 32.5936 Q1789.83 32.5936 1786.47 36.4824 Q1783.11 40.3308 1783.11 46.9338 L1783.11 72.576 L1775.61 72.576 L1775.61 27.2059 L1783.11 27.2059 L1783.11 34.2544 Q1785.66 30.082 1789.22 28.0971 Q1792.79 26.1121 1797.69 26.1121 Q1802.63 26.1121 1806.07 28.6237 Q1809.56 31.1352 1811.22 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M1895.52 48.0275 L1895.52 51.6733 L1861.25 51.6733 Q1861.73 59.3701 1865.87 63.421 Q1870.04 67.4314 1877.45 67.4314 Q1881.74 67.4314 1885.76 66.3781 Q1889.81 65.3249 1893.78 63.2184 L1893.78 70.267 Q1889.77 71.9684 1885.55 72.8596 Q1881.34 73.7508 1877.01 73.7508 Q1866.15 73.7508 1859.79 67.4314 Q1853.47 61.1119 1853.47 50.3365 Q1853.47 39.1965 1859.46 32.6746 Q1865.5 26.1121 1875.71 26.1121 Q1884.86 26.1121 1890.17 32.0264 Q1895.52 37.9003 1895.52 48.0275 M1888.06 45.84 Q1887.98 39.7232 1884.62 36.0774 Q1881.3 32.4315 1875.79 32.4315 Q1869.55 32.4315 1865.78 35.9558 Q1862.06 39.4801 1861.49 45.8805 L1888.06 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip212)\" d=\"M295.211 1386.4 L790.663 1331.91 L790.663 1320.12 L295.211 1382  Z\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"0.2\"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"295.211,1384.2 790.663,1326.02 \"/>\n",
       "<path clip-path=\"url(#clip212)\" d=\"M1289.58 634.444 L2292.83 187.149 L1202.7 1049.28 L1202.7 1037.62 L2292.83 160.256 L1289.58 609.067  Z\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"0.2\"/>\n",
       "<polyline clip-path=\"url(#clip212)\" style=\"stroke:#e26f46; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1289.58,621.756 2292.83,173.703 1202.7,1043.45 \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M305.865 322.316 L617.057 322.316 L617.057 166.796 L305.865 166.796  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"305.865,322.316 617.057,322.316 617.057,166.796 305.865,166.796 305.865,322.316 \"/>\n",
       "<polyline clip-path=\"url(#clip210)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"329.393,218.636 470.558,218.636 \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M494.085 209.99 L498.599 209.99 L506.701 231.749 L514.803 209.99 L519.316 209.99 L509.594 235.916 L503.807 235.916 L494.085 209.99 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M525.196 209.99 L529.455 209.99 L529.455 235.916 L525.196 235.916 L525.196 209.99 M525.196 199.897 L529.455 199.897 L529.455 205.291 L525.196 205.291 L525.196 199.897 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip210)\" style=\"stroke:#e26f46; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"329.393,270.476 470.558,270.476 \"/>\n",
       "<path clip-path=\"url(#clip210)\" d=\"M512.858 274.816 Q512.858 270.117 510.914 267.455 Q508.992 264.77 505.613 264.77 Q502.233 264.77 500.289 267.455 Q498.367 270.117 498.367 274.816 Q498.367 279.515 500.289 282.2 Q502.233 284.862 505.613 284.862 Q508.992 284.862 510.914 282.2 Q512.858 279.515 512.858 274.816 M498.367 265.765 Q499.71 263.45 501.747 262.339 Q503.807 261.205 506.654 261.205 Q511.377 261.205 514.316 264.955 Q517.279 268.705 517.279 274.816 Q517.279 280.927 514.316 284.677 Q511.377 288.427 506.654 288.427 Q503.807 288.427 501.747 287.316 Q499.71 286.182 498.367 283.867 L498.367 287.756 L494.085 287.756 L494.085 251.737 L498.367 251.737 L498.367 265.765 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M524.34 251.737 L528.599 251.737 L528.599 287.756 L524.34 287.756 L524.34 251.737 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M557.21 295.626 L557.21 298.936 L532.58 298.936 L532.58 295.626 L557.21 295.626 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M558.159 261.83 L562.673 261.83 L570.775 283.589 L578.876 261.83 L583.39 261.83 L573.668 287.756 L567.881 287.756 L558.159 261.83 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip210)\" d=\"M589.27 261.83 L593.529 261.83 L593.529 287.756 L589.27 287.756 L589.27 261.83 M589.27 251.737 L593.529 251.737 L593.529 257.131 L589.27 257.131 L589.27 251.737 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
      ],
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip260\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M0 1600 L2400 1600 L2400 0 L0 0  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip261\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M235.283 1423.18 L2352.76 1423.18 L2352.76 123.472 L235.283 123.472  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip262\">\n",
       "    <rect x=\"235\" y=\"123\" width=\"2118\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"502.724,1423.18 502.724,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"853.608,1423.18 853.608,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1204.49,1423.18 1204.49,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1555.38,1423.18 1555.38,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1906.26,1423.18 1906.26,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2257.14,1423.18 2257.14,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1423.18 2352.76,1423.18 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"502.724,1423.18 502.724,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"853.608,1423.18 853.608,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1204.49,1423.18 1204.49,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1555.38,1423.18 1555.38,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1906.26,1423.18 1906.26,1404.28 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2257.14,1423.18 2257.14,1404.28 \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M480.722 1454.1 Q477.111 1454.1 475.282 1457.66 Q473.477 1461.2 473.477 1468.33 Q473.477 1475.44 475.282 1479.01 Q477.111 1482.55 480.722 1482.55 Q484.356 1482.55 486.162 1479.01 Q487.99 1475.44 487.99 1468.33 Q487.99 1461.2 486.162 1457.66 Q484.356 1454.1 480.722 1454.1 M480.722 1450.39 Q486.532 1450.39 489.588 1455 Q492.666 1459.58 492.666 1468.33 Q492.666 1477.06 489.588 1481.67 Q486.532 1486.25 480.722 1486.25 Q474.912 1486.25 471.833 1481.67 Q468.778 1477.06 468.778 1468.33 Q468.778 1459.58 471.833 1455 Q474.912 1450.39 480.722 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M500.884 1479.7 L505.768 1479.7 L505.768 1485.58 L500.884 1485.58 L500.884 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M516.763 1481.64 L524.402 1481.64 L524.402 1455.28 L516.092 1456.95 L516.092 1452.69 L524.356 1451.02 L529.032 1451.02 L529.032 1481.64 L536.671 1481.64 L536.671 1485.58 L516.763 1485.58 L516.763 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M831.791 1454.1 Q828.18 1454.1 826.352 1457.66 Q824.546 1461.2 824.546 1468.33 Q824.546 1475.44 826.352 1479.01 Q828.18 1482.55 831.791 1482.55 Q835.426 1482.55 837.231 1479.01 Q839.06 1475.44 839.06 1468.33 Q839.06 1461.2 837.231 1457.66 Q835.426 1454.1 831.791 1454.1 M831.791 1450.39 Q837.601 1450.39 840.657 1455 Q843.736 1459.58 843.736 1468.33 Q843.736 1477.06 840.657 1481.67 Q837.601 1486.25 831.791 1486.25 Q825.981 1486.25 822.902 1481.67 Q819.847 1477.06 819.847 1468.33 Q819.847 1459.58 822.902 1455 Q825.981 1450.39 831.791 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M851.953 1479.7 L856.837 1479.7 L856.837 1485.58 L851.953 1485.58 L851.953 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M871.05 1481.64 L887.37 1481.64 L887.37 1485.58 L865.425 1485.58 L865.425 1481.64 Q868.087 1478.89 872.671 1474.26 Q877.277 1469.61 878.458 1468.27 Q880.703 1465.74 881.583 1464.01 Q882.485 1462.25 882.485 1460.56 Q882.485 1457.8 880.541 1456.07 Q878.62 1454.33 875.518 1454.33 Q873.319 1454.33 870.865 1455.09 Q868.435 1455.86 865.657 1457.41 L865.657 1452.69 Q868.481 1451.55 870.935 1450.97 Q873.388 1450.39 875.425 1450.39 Q880.796 1450.39 883.99 1453.08 Q887.185 1455.77 887.185 1460.26 Q887.185 1462.39 886.374 1464.31 Q885.587 1466.2 883.481 1468.8 Q882.902 1469.47 879.8 1472.69 Q876.698 1475.88 871.05 1481.64 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1182.2 1454.1 Q1178.59 1454.1 1176.76 1457.66 Q1174.96 1461.2 1174.96 1468.33 Q1174.96 1475.44 1176.76 1479.01 Q1178.59 1482.55 1182.2 1482.55 Q1185.84 1482.55 1187.64 1479.01 Q1189.47 1475.44 1189.47 1468.33 Q1189.47 1461.2 1187.64 1457.66 Q1185.84 1454.1 1182.2 1454.1 M1182.2 1450.39 Q1188.01 1450.39 1191.07 1455 Q1194.15 1459.58 1194.15 1468.33 Q1194.15 1477.06 1191.07 1481.67 Q1188.01 1486.25 1182.2 1486.25 Q1176.39 1486.25 1173.31 1481.67 Q1170.26 1477.06 1170.26 1468.33 Q1170.26 1459.58 1173.31 1455 Q1176.39 1450.39 1182.2 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1202.36 1479.7 L1207.25 1479.7 L1207.25 1485.58 L1202.36 1485.58 L1202.36 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1231.6 1466.95 Q1234.96 1467.66 1236.83 1469.93 Q1238.73 1472.2 1238.73 1475.53 Q1238.73 1480.65 1235.21 1483.45 Q1231.69 1486.25 1225.21 1486.25 Q1223.03 1486.25 1220.72 1485.81 Q1218.43 1485.39 1215.97 1484.54 L1215.97 1480.02 Q1217.92 1481.16 1220.23 1481.74 Q1222.55 1482.32 1225.07 1482.32 Q1229.47 1482.32 1231.76 1480.58 Q1234.08 1478.84 1234.08 1475.53 Q1234.08 1472.48 1231.92 1470.77 Q1229.79 1469.03 1225.97 1469.03 L1221.95 1469.03 L1221.95 1465.19 L1226.16 1465.19 Q1229.61 1465.19 1231.44 1463.82 Q1233.27 1462.43 1233.27 1459.84 Q1233.27 1457.18 1231.37 1455.77 Q1229.49 1454.33 1225.97 1454.33 Q1224.05 1454.33 1221.85 1454.75 Q1219.65 1455.16 1217.02 1456.04 L1217.02 1451.88 Q1219.68 1451.14 1221.99 1450.77 Q1224.33 1450.39 1226.39 1450.39 Q1231.71 1450.39 1234.82 1452.83 Q1237.92 1455.23 1237.92 1459.35 Q1237.92 1462.22 1236.27 1464.21 Q1234.63 1466.18 1231.6 1466.95 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1532.52 1454.1 Q1528.91 1454.1 1527.08 1457.66 Q1525.27 1461.2 1525.27 1468.33 Q1525.27 1475.44 1527.08 1479.01 Q1528.91 1482.55 1532.52 1482.55 Q1536.15 1482.55 1537.96 1479.01 Q1539.79 1475.44 1539.79 1468.33 Q1539.79 1461.2 1537.96 1457.66 Q1536.15 1454.1 1532.52 1454.1 M1532.52 1450.39 Q1538.33 1450.39 1541.38 1455 Q1544.46 1459.58 1544.46 1468.33 Q1544.46 1477.06 1541.38 1481.67 Q1538.33 1486.25 1532.52 1486.25 Q1526.71 1486.25 1523.63 1481.67 Q1520.57 1477.06 1520.57 1468.33 Q1520.57 1459.58 1523.63 1455 Q1526.71 1450.39 1532.52 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1552.68 1479.7 L1557.56 1479.7 L1557.56 1485.58 L1552.68 1485.58 L1552.68 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1580.6 1455.09 L1568.79 1473.54 L1580.6 1473.54 L1580.6 1455.09 M1579.37 1451.02 L1585.25 1451.02 L1585.25 1473.54 L1590.18 1473.54 L1590.18 1477.43 L1585.25 1477.43 L1585.25 1485.58 L1580.6 1485.58 L1580.6 1477.43 L1564.99 1477.43 L1564.99 1472.92 L1579.37 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1884.14 1454.1 Q1880.53 1454.1 1878.7 1457.66 Q1876.9 1461.2 1876.9 1468.33 Q1876.9 1475.44 1878.7 1479.01 Q1880.53 1482.55 1884.14 1482.55 Q1887.78 1482.55 1889.58 1479.01 Q1891.41 1475.44 1891.41 1468.33 Q1891.41 1461.2 1889.58 1457.66 Q1887.78 1454.1 1884.14 1454.1 M1884.14 1450.39 Q1889.95 1450.39 1893.01 1455 Q1896.09 1459.58 1896.09 1468.33 Q1896.09 1477.06 1893.01 1481.67 Q1889.95 1486.25 1884.14 1486.25 Q1878.33 1486.25 1875.25 1481.67 Q1872.2 1477.06 1872.2 1468.33 Q1872.2 1459.58 1875.25 1455 Q1878.33 1450.39 1884.14 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1904.3 1479.7 L1909.19 1479.7 L1909.19 1485.58 L1904.3 1485.58 L1904.3 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1919.42 1451.02 L1937.78 1451.02 L1937.78 1454.96 L1923.7 1454.96 L1923.7 1463.43 Q1924.72 1463.08 1925.74 1462.92 Q1926.76 1462.73 1927.78 1462.73 Q1933.56 1462.73 1936.94 1465.9 Q1940.32 1469.08 1940.32 1474.49 Q1940.32 1480.07 1936.85 1483.17 Q1933.38 1486.25 1927.06 1486.25 Q1924.88 1486.25 1922.61 1485.88 Q1920.37 1485.51 1917.96 1484.77 L1917.96 1480.07 Q1920.05 1481.2 1922.27 1481.76 Q1924.49 1482.32 1926.97 1482.32 Q1930.97 1482.32 1933.31 1480.21 Q1935.65 1478.1 1935.65 1474.49 Q1935.65 1470.88 1933.31 1468.77 Q1930.97 1466.67 1926.97 1466.67 Q1925.09 1466.67 1923.22 1467.08 Q1921.36 1467.5 1919.42 1468.38 L1919.42 1451.02 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2234.45 1454.1 Q2230.84 1454.1 2229.01 1457.66 Q2227.2 1461.2 2227.2 1468.33 Q2227.2 1475.44 2229.01 1479.01 Q2230.84 1482.55 2234.45 1482.55 Q2238.08 1482.55 2239.89 1479.01 Q2241.72 1475.44 2241.72 1468.33 Q2241.72 1461.2 2239.89 1457.66 Q2238.08 1454.1 2234.45 1454.1 M2234.45 1450.39 Q2240.26 1450.39 2243.31 1455 Q2246.39 1459.58 2246.39 1468.33 Q2246.39 1477.06 2243.31 1481.67 Q2240.26 1486.25 2234.45 1486.25 Q2228.64 1486.25 2225.56 1481.67 Q2222.5 1477.06 2222.5 1468.33 Q2222.5 1459.58 2225.56 1455 Q2228.64 1450.39 2234.45 1450.39 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2254.61 1479.7 L2259.49 1479.7 L2259.49 1485.58 L2254.61 1485.58 L2254.61 1479.7 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M2280.26 1466.44 Q2277.11 1466.44 2275.26 1468.59 Q2273.43 1470.74 2273.43 1474.49 Q2273.43 1478.22 2275.26 1480.39 Q2277.11 1482.55 2280.26 1482.55 Q2283.41 1482.55 2285.23 1480.39 Q2287.09 1478.22 2287.09 1474.49 Q2287.09 1470.74 2285.23 1468.59 Q2283.41 1466.44 2280.26 1466.44 M2289.54 1451.78 L2289.54 1456.04 Q2287.78 1455.21 2285.98 1454.77 Q2284.19 1454.33 2282.43 1454.33 Q2277.8 1454.33 2275.35 1457.45 Q2272.92 1460.58 2272.57 1466.9 Q2273.94 1464.89 2276 1463.82 Q2278.06 1462.73 2280.54 1462.73 Q2285.74 1462.73 2288.75 1465.9 Q2291.79 1469.05 2291.79 1474.49 Q2291.79 1479.82 2288.64 1483.03 Q2285.49 1486.25 2280.26 1486.25 Q2274.26 1486.25 2271.09 1481.67 Q2267.92 1477.06 2267.92 1468.33 Q2267.92 1460.14 2271.81 1455.28 Q2275.7 1450.39 2282.25 1450.39 Q2284.01 1450.39 2285.79 1450.74 Q2287.6 1451.09 2289.54 1451.78 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M983.914 1533.76 L983.914 1539.24 Q981.431 1537.87 978.917 1537.2 Q976.434 1536.5 973.888 1536.5 Q968.191 1536.5 965.04 1540.13 Q961.889 1543.73 961.889 1550.25 Q961.889 1556.78 965.04 1560.4 Q968.191 1564 973.888 1564 Q976.434 1564 978.917 1563.33 Q981.431 1562.63 983.914 1561.26 L983.914 1566.68 Q981.463 1567.82 978.821 1568.39 Q976.211 1568.97 973.251 1568.97 Q965.199 1568.97 960.456 1563.91 Q955.714 1558.85 955.714 1550.25 Q955.714 1541.53 960.488 1536.53 Q965.294 1531.54 973.633 1531.54 Q976.339 1531.54 978.917 1532.11 Q981.495 1532.65 983.914 1533.76 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1007.91 1536.5 Q1003.2 1536.5 1000.46 1540.19 Q997.728 1543.85 997.728 1550.25 Q997.728 1556.65 1000.43 1560.34 Q1003.17 1564 1007.91 1564 Q1012.59 1564 1015.33 1560.31 Q1018.07 1556.62 1018.07 1550.25 Q1018.07 1543.92 1015.33 1540.23 Q1012.59 1536.5 1007.91 1536.5 M1007.91 1531.54 Q1015.55 1531.54 1019.91 1536.5 Q1024.27 1541.47 1024.27 1550.25 Q1024.27 1559 1019.91 1564 Q1015.55 1568.97 1007.91 1568.97 Q1000.24 1568.97 995.882 1564 Q991.553 1559 991.553 1550.25 Q991.553 1541.47 995.882 1536.5 Q1000.24 1531.54 1007.91 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1061.73 1539.24 Q1063.93 1535.29 1066.99 1533.41 Q1070.04 1531.54 1074.18 1531.54 Q1079.75 1531.54 1082.77 1535.45 Q1085.8 1539.33 1085.8 1546.53 L1085.8 1568.04 L1079.91 1568.04 L1079.91 1546.72 Q1079.91 1541.59 1078.09 1539.11 Q1076.28 1536.63 1072.56 1536.63 Q1068 1536.63 1065.36 1539.65 Q1062.72 1542.68 1062.72 1547.9 L1062.72 1568.04 L1056.83 1568.04 L1056.83 1546.72 Q1056.83 1541.56 1055.02 1539.11 Q1053.2 1536.63 1049.42 1536.63 Q1044.93 1536.63 1042.29 1539.68 Q1039.65 1542.71 1039.65 1547.9 L1039.65 1568.04 L1033.76 1568.04 L1033.76 1532.4 L1039.65 1532.4 L1039.65 1537.93 Q1041.65 1534.66 1044.45 1533.1 Q1047.25 1531.54 1051.1 1531.54 Q1054.99 1531.54 1057.69 1533.51 Q1060.43 1535.48 1061.73 1539.24 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1103.14 1562.7 L1103.14 1581.6 L1097.26 1581.6 L1097.26 1532.4 L1103.14 1532.4 L1103.14 1537.81 Q1104.99 1534.62 1107.79 1533.1 Q1110.62 1531.54 1114.54 1531.54 Q1121.03 1531.54 1125.07 1536.69 Q1129.15 1541.85 1129.15 1550.25 Q1129.15 1558.65 1125.07 1563.81 Q1121.03 1568.97 1114.54 1568.97 Q1110.62 1568.97 1107.79 1567.44 Q1104.99 1565.88 1103.14 1562.7 M1123.07 1550.25 Q1123.07 1543.79 1120.39 1540.13 Q1117.75 1536.44 1113.11 1536.44 Q1108.46 1536.44 1105.79 1540.13 Q1103.14 1543.79 1103.14 1550.25 Q1103.14 1556.71 1105.79 1560.4 Q1108.46 1564.07 1113.11 1564.07 Q1117.75 1564.07 1120.39 1560.4 Q1123.07 1556.71 1123.07 1550.25 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1138.25 1553.98 L1138.25 1532.4 L1144.11 1532.4 L1144.11 1553.75 Q1144.11 1558.81 1146.08 1561.36 Q1148.05 1563.87 1152 1563.87 Q1156.74 1563.87 1159.48 1560.85 Q1162.25 1557.83 1162.25 1552.61 L1162.25 1532.4 L1168.11 1532.4 L1168.11 1568.04 L1162.25 1568.04 L1162.25 1562.57 Q1160.12 1565.82 1157.28 1567.41 Q1154.48 1568.97 1150.76 1568.97 Q1144.62 1568.97 1141.43 1565.15 Q1138.25 1561.33 1138.25 1553.98 M1152.99 1531.54 L1152.99 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1185.96 1522.27 L1185.96 1532.4 L1198.02 1532.4 L1198.02 1536.95 L1185.96 1536.95 L1185.96 1556.3 Q1185.96 1560.66 1187.14 1561.9 Q1188.35 1563.14 1192.01 1563.14 L1198.02 1563.14 L1198.02 1568.04 L1192.01 1568.04 Q1185.23 1568.04 1182.65 1565.53 Q1180.07 1562.98 1180.07 1556.3 L1180.07 1536.95 L1175.78 1536.95 L1175.78 1532.4 L1180.07 1532.4 L1180.07 1522.27 L1185.96 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1221.93 1550.12 Q1214.83 1550.12 1212.09 1551.75 Q1209.36 1553.37 1209.36 1557.29 Q1209.36 1560.4 1211.39 1562.25 Q1213.46 1564.07 1216.99 1564.07 Q1221.86 1564.07 1224.79 1560.63 Q1227.75 1557.16 1227.75 1551.43 L1227.75 1550.12 L1221.93 1550.12 M1233.61 1547.71 L1233.61 1568.04 L1227.75 1568.04 L1227.75 1562.63 Q1225.75 1565.88 1222.76 1567.44 Q1219.76 1568.97 1215.43 1568.97 Q1209.96 1568.97 1206.71 1565.91 Q1203.5 1562.82 1203.5 1557.67 Q1203.5 1551.65 1207.51 1548.6 Q1211.55 1545.54 1219.54 1545.54 L1227.75 1545.54 L1227.75 1544.97 Q1227.75 1540.93 1225.08 1538.73 Q1222.44 1536.5 1217.63 1536.5 Q1214.58 1536.5 1211.68 1537.23 Q1208.78 1537.97 1206.11 1539.43 L1206.11 1534.02 Q1209.32 1532.78 1212.35 1532.17 Q1215.37 1531.54 1218.24 1531.54 Q1225.97 1531.54 1229.79 1535.55 Q1233.61 1539.56 1233.61 1547.71 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1251.46 1522.27 L1251.46 1532.4 L1263.53 1532.4 L1263.53 1536.95 L1251.46 1536.95 L1251.46 1556.3 Q1251.46 1560.66 1252.64 1561.9 Q1253.85 1563.14 1257.51 1563.14 L1263.53 1563.14 L1263.53 1568.04 L1257.51 1568.04 Q1250.73 1568.04 1248.15 1565.53 Q1245.58 1562.98 1245.58 1556.3 L1245.58 1536.95 L1241.28 1536.95 L1241.28 1532.4 L1245.58 1532.4 L1245.58 1522.27 L1251.46 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1271.23 1532.4 L1277.09 1532.4 L1277.09 1568.04 L1271.23 1568.04 L1271.23 1532.4 M1271.23 1518.52 L1277.09 1518.52 L1277.09 1525.93 L1271.23 1525.93 L1271.23 1518.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1303.15 1536.5 Q1298.44 1536.5 1295.71 1540.19 Q1292.97 1543.85 1292.97 1550.25 Q1292.97 1556.65 1295.67 1560.34 Q1298.41 1564 1303.15 1564 Q1307.83 1564 1310.57 1560.31 Q1313.31 1556.62 1313.31 1550.25 Q1313.31 1543.92 1310.57 1540.23 Q1307.83 1536.5 1303.15 1536.5 M1303.15 1531.54 Q1310.79 1531.54 1315.15 1536.5 Q1319.51 1541.47 1319.51 1550.25 Q1319.51 1559 1315.15 1564 Q1310.79 1568.97 1303.15 1568.97 Q1295.48 1568.97 1291.12 1564 Q1286.79 1559 1286.79 1550.25 Q1286.79 1541.47 1291.12 1536.5 Q1295.48 1531.54 1303.15 1531.54 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1358.85 1546.53 L1358.85 1568.04 L1353 1568.04 L1353 1546.72 Q1353 1541.66 1351.02 1539.14 Q1349.05 1536.63 1345.1 1536.63 Q1340.36 1536.63 1337.62 1539.65 Q1334.89 1542.68 1334.89 1547.9 L1334.89 1568.04 L1329 1568.04 L1329 1532.4 L1334.89 1532.4 L1334.89 1537.93 Q1336.99 1534.72 1339.82 1533.13 Q1342.69 1531.54 1346.41 1531.54 Q1352.55 1531.54 1355.7 1535.36 Q1358.85 1539.14 1358.85 1546.53 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1397.05 1522.27 L1397.05 1532.4 L1409.11 1532.4 L1409.11 1536.95 L1397.05 1536.95 L1397.05 1556.3 Q1397.05 1560.66 1398.23 1561.9 Q1399.44 1563.14 1403.1 1563.14 L1409.11 1563.14 L1409.11 1568.04 L1403.1 1568.04 Q1396.32 1568.04 1393.74 1565.53 Q1391.16 1562.98 1391.16 1556.3 L1391.16 1536.95 L1386.86 1536.95 L1386.86 1532.4 L1391.16 1532.4 L1391.16 1522.27 L1397.05 1522.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1416.81 1532.4 L1422.67 1532.4 L1422.67 1568.04 L1416.81 1568.04 L1416.81 1532.4 M1416.81 1518.52 L1422.67 1518.52 L1422.67 1525.93 L1416.81 1525.93 L1416.81 1518.52 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1462.68 1539.24 Q1464.87 1535.29 1467.93 1533.41 Q1470.99 1531.54 1475.12 1531.54 Q1480.69 1531.54 1483.72 1535.45 Q1486.74 1539.33 1486.74 1546.53 L1486.74 1568.04 L1480.85 1568.04 L1480.85 1546.72 Q1480.85 1541.59 1479.04 1539.11 Q1477.22 1536.63 1473.5 1536.63 Q1468.95 1536.63 1466.31 1539.65 Q1463.67 1542.68 1463.67 1547.9 L1463.67 1568.04 L1457.78 1568.04 L1457.78 1546.72 Q1457.78 1541.56 1455.96 1539.11 Q1454.15 1536.63 1450.36 1536.63 Q1445.87 1536.63 1443.23 1539.68 Q1440.59 1542.71 1440.59 1547.9 L1440.59 1568.04 L1434.7 1568.04 L1434.7 1532.4 L1440.59 1532.4 L1440.59 1537.93 Q1442.59 1534.66 1445.4 1533.1 Q1448.2 1531.54 1452.05 1531.54 Q1455.93 1531.54 1458.64 1533.51 Q1461.37 1535.48 1462.68 1539.24 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1528.91 1548.76 L1528.91 1551.62 L1501.99 1551.62 Q1502.37 1557.67 1505.62 1560.85 Q1508.89 1564 1514.72 1564 Q1518.09 1564 1521.24 1563.17 Q1524.43 1562.35 1527.55 1560.69 L1527.55 1566.23 Q1524.39 1567.57 1521.08 1568.27 Q1517.77 1568.97 1514.37 1568.97 Q1505.84 1568.97 1500.84 1564 Q1495.88 1559.04 1495.88 1550.57 Q1495.88 1541.82 1500.59 1536.69 Q1505.33 1531.54 1513.35 1531.54 Q1520.54 1531.54 1524.71 1536.18 Q1528.91 1540.8 1528.91 1548.76 M1523.06 1547.04 Q1522.99 1542.23 1520.35 1539.37 Q1517.74 1536.5 1513.41 1536.5 Q1508.51 1536.5 1505.55 1539.27 Q1502.62 1542.04 1502.18 1547.07 L1523.06 1547.04 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1573.31 1518.58 Q1569.05 1525.9 1566.98 1533.06 Q1564.91 1540.23 1564.91 1547.58 Q1564.91 1554.93 1566.98 1562.16 Q1569.08 1569.35 1573.31 1576.64 L1568.22 1576.64 Q1563.45 1569.16 1561.06 1561.93 Q1558.71 1554.71 1558.71 1547.58 Q1558.71 1540.48 1561.06 1533.29 Q1563.42 1526.09 1568.22 1518.58 L1573.31 1518.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1607.4 1533.45 L1607.4 1538.98 Q1604.92 1537.71 1602.25 1537.07 Q1599.57 1536.44 1596.71 1536.44 Q1592.35 1536.44 1590.15 1537.77 Q1587.99 1539.11 1587.99 1541.79 Q1587.99 1543.82 1589.55 1545 Q1591.11 1546.15 1595.82 1547.2 L1597.82 1547.64 Q1604.06 1548.98 1606.67 1551.43 Q1609.31 1553.85 1609.31 1558.21 Q1609.31 1563.17 1605.37 1566.07 Q1601.45 1568.97 1594.58 1568.97 Q1591.71 1568.97 1588.59 1568.39 Q1585.51 1567.85 1582.07 1566.74 L1582.07 1560.69 Q1585.31 1562.38 1588.47 1563.24 Q1591.62 1564.07 1594.7 1564.07 Q1598.84 1564.07 1601.07 1562.66 Q1603.3 1561.23 1603.3 1558.65 Q1603.3 1556.27 1601.67 1554.99 Q1600.08 1553.72 1594.64 1552.54 L1592.6 1552.07 Q1587.16 1550.92 1584.74 1548.56 Q1582.32 1546.18 1582.32 1542.04 Q1582.32 1537.01 1585.89 1534.27 Q1589.45 1531.54 1596.01 1531.54 Q1599.26 1531.54 1602.12 1532.01 Q1604.98 1532.49 1607.4 1533.45 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1617.72 1518.58 L1622.81 1518.58 Q1627.58 1526.09 1629.94 1533.29 Q1632.32 1540.48 1632.32 1547.58 Q1632.32 1554.71 1629.94 1561.93 Q1627.58 1569.16 1622.81 1576.64 L1617.72 1576.64 Q1621.95 1569.35 1624.02 1562.16 Q1626.12 1554.93 1626.12 1547.58 Q1626.12 1540.23 1624.02 1533.06 Q1621.95 1525.9 1617.72 1518.58 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,1386.08 2352.76,1386.08 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,1122.52 2352.76,1122.52 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,858.96 2352.76,858.96 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,595.4 2352.76,595.4 \"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"235.283,331.839 2352.76,331.839 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1423.18 235.283,123.472 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1386.08 254.18,1386.08 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,1122.52 254.18,1122.52 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,858.96 254.18,858.96 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,595.4 254.18,595.4 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"235.283,331.839 254.18,331.839 \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M187.338 1371.88 Q183.727 1371.88 181.899 1375.45 Q180.093 1378.99 180.093 1386.12 Q180.093 1393.22 181.899 1396.79 Q183.727 1400.33 187.338 1400.33 Q190.973 1400.33 192.778 1396.79 Q194.607 1393.22 194.607 1386.12 Q194.607 1378.99 192.778 1375.45 Q190.973 1371.88 187.338 1371.88 M187.338 1368.18 Q193.149 1368.18 196.204 1372.78 Q199.283 1377.37 199.283 1386.12 Q199.283 1394.84 196.204 1399.45 Q193.149 1404.03 187.338 1404.03 Q181.528 1404.03 178.45 1399.45 Q175.394 1394.84 175.394 1386.12 Q175.394 1377.37 178.45 1372.78 Q181.528 1368.18 187.338 1368.18 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M117.825 1135.87 L125.464 1135.87 L125.464 1109.5 L117.154 1111.17 L117.154 1106.91 L125.418 1105.24 L130.093 1105.24 L130.093 1135.87 L137.732 1135.87 L137.732 1139.8 L117.825 1139.8 L117.825 1135.87 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.177 1108.32 Q153.566 1108.32 151.737 1111.88 Q149.931 1115.43 149.931 1122.56 Q149.931 1129.66 151.737 1133.23 Q153.566 1136.77 157.177 1136.77 Q160.811 1136.77 162.616 1133.23 Q164.445 1129.66 164.445 1122.56 Q164.445 1115.43 162.616 1111.88 Q160.811 1108.32 157.177 1108.32 M157.177 1104.62 Q162.987 1104.62 166.042 1109.22 Q169.121 1113.81 169.121 1122.56 Q169.121 1131.28 166.042 1135.89 Q162.987 1140.47 157.177 1140.47 Q151.366 1140.47 148.288 1135.89 Q145.232 1131.28 145.232 1122.56 Q145.232 1113.81 148.288 1109.22 Q151.366 1104.62 157.177 1104.62 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M187.338 1108.32 Q183.727 1108.32 181.899 1111.88 Q180.093 1115.43 180.093 1122.56 Q180.093 1129.66 181.899 1133.23 Q183.727 1136.77 187.338 1136.77 Q190.973 1136.77 192.778 1133.23 Q194.607 1129.66 194.607 1122.56 Q194.607 1115.43 192.778 1111.88 Q190.973 1108.32 187.338 1108.32 M187.338 1104.62 Q193.149 1104.62 196.204 1109.22 Q199.283 1113.81 199.283 1122.56 Q199.283 1131.28 196.204 1135.89 Q193.149 1140.47 187.338 1140.47 Q181.528 1140.47 178.45 1135.89 Q175.394 1131.28 175.394 1122.56 Q175.394 1113.81 178.45 1109.22 Q181.528 1104.62 187.338 1104.62 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M121.043 872.305 L137.362 872.305 L137.362 876.24 L115.418 876.24 L115.418 872.305 Q118.08 869.551 122.663 864.921 Q127.269 860.268 128.45 858.926 Q130.695 856.402 131.575 854.666 Q132.478 852.907 132.478 851.217 Q132.478 848.463 130.533 846.727 Q128.612 844.99 125.51 844.99 Q123.311 844.99 120.857 845.754 Q118.427 846.518 115.649 848.069 L115.649 843.347 Q118.473 842.213 120.927 841.634 Q123.38 841.055 125.418 841.055 Q130.788 841.055 133.982 843.74 Q137.177 846.426 137.177 850.916 Q137.177 853.046 136.367 854.967 Q135.579 856.865 133.473 859.458 Q132.894 860.129 129.792 863.347 Q126.691 866.541 121.043 872.305 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.177 844.759 Q153.566 844.759 151.737 848.324 Q149.931 851.865 149.931 858.995 Q149.931 866.101 151.737 869.666 Q153.566 873.208 157.177 873.208 Q160.811 873.208 162.616 869.666 Q164.445 866.101 164.445 858.995 Q164.445 851.865 162.616 848.324 Q160.811 844.759 157.177 844.759 M157.177 841.055 Q162.987 841.055 166.042 845.662 Q169.121 850.245 169.121 858.995 Q169.121 867.722 166.042 872.328 Q162.987 876.912 157.177 876.912 Q151.366 876.912 148.288 872.328 Q145.232 867.722 145.232 858.995 Q145.232 850.245 148.288 845.662 Q151.366 841.055 157.177 841.055 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M187.338 844.759 Q183.727 844.759 181.899 848.324 Q180.093 851.865 180.093 858.995 Q180.093 866.101 181.899 869.666 Q183.727 873.208 187.338 873.208 Q190.973 873.208 192.778 869.666 Q194.607 866.101 194.607 858.995 Q194.607 851.865 192.778 848.324 Q190.973 844.759 187.338 844.759 M187.338 841.055 Q193.149 841.055 196.204 845.662 Q199.283 850.245 199.283 858.995 Q199.283 867.722 196.204 872.328 Q193.149 876.912 187.338 876.912 Q181.528 876.912 178.45 872.328 Q175.394 867.722 175.394 858.995 Q175.394 850.245 178.45 845.662 Q181.528 841.055 187.338 841.055 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M131.181 594.046 Q134.538 594.763 136.413 597.032 Q138.311 599.3 138.311 602.633 Q138.311 607.749 134.792 610.55 Q131.274 613.351 124.793 613.351 Q122.617 613.351 120.302 612.911 Q118.01 612.494 115.556 611.638 L115.556 607.124 Q117.501 608.258 119.816 608.837 Q122.13 609.416 124.654 609.416 Q129.052 609.416 131.343 607.68 Q133.658 605.944 133.658 602.633 Q133.658 599.578 131.505 597.865 Q129.376 596.129 125.556 596.129 L121.529 596.129 L121.529 592.286 L125.742 592.286 Q129.191 592.286 131.019 590.921 Q132.848 589.532 132.848 586.939 Q132.848 584.277 130.95 582.865 Q129.075 581.43 125.556 581.43 Q123.635 581.43 121.436 581.847 Q119.237 582.263 116.598 583.143 L116.598 578.976 Q119.26 578.235 121.575 577.865 Q123.913 577.495 125.973 577.495 Q131.297 577.495 134.399 579.925 Q137.501 582.333 137.501 586.453 Q137.501 589.323 135.857 591.314 Q134.214 593.282 131.181 594.046 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.177 581.198 Q153.566 581.198 151.737 584.763 Q149.931 588.305 149.931 595.434 Q149.931 602.541 151.737 606.106 Q153.566 609.647 157.177 609.647 Q160.811 609.647 162.616 606.106 Q164.445 602.541 164.445 595.434 Q164.445 588.305 162.616 584.763 Q160.811 581.198 157.177 581.198 M157.177 577.495 Q162.987 577.495 166.042 582.101 Q169.121 586.684 169.121 595.434 Q169.121 604.161 166.042 608.768 Q162.987 613.351 157.177 613.351 Q151.366 613.351 148.288 608.768 Q145.232 604.161 145.232 595.434 Q145.232 586.684 148.288 582.101 Q151.366 577.495 157.177 577.495 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M187.338 581.198 Q183.727 581.198 181.899 584.763 Q180.093 588.305 180.093 595.434 Q180.093 602.541 181.899 606.106 Q183.727 609.647 187.338 609.647 Q190.973 609.647 192.778 606.106 Q194.607 602.541 194.607 595.434 Q194.607 588.305 192.778 584.763 Q190.973 581.198 187.338 581.198 M187.338 577.495 Q193.149 577.495 196.204 582.101 Q199.283 586.684 199.283 595.434 Q199.283 604.161 196.204 608.768 Q193.149 613.351 187.338 613.351 Q181.528 613.351 178.45 608.768 Q175.394 604.161 175.394 595.434 Q175.394 586.684 178.45 582.101 Q181.528 577.495 187.338 577.495 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M129.862 318.633 L118.056 337.082 L129.862 337.082 L129.862 318.633 M128.635 314.559 L134.515 314.559 L134.515 337.082 L139.445 337.082 L139.445 340.971 L134.515 340.971 L134.515 349.119 L129.862 349.119 L129.862 340.971 L114.26 340.971 L114.26 336.457 L128.635 314.559 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M157.177 317.638 Q153.566 317.638 151.737 321.203 Q149.931 324.744 149.931 331.874 Q149.931 338.98 151.737 342.545 Q153.566 346.087 157.177 346.087 Q160.811 346.087 162.616 342.545 Q164.445 338.98 164.445 331.874 Q164.445 324.744 162.616 321.203 Q160.811 317.638 157.177 317.638 M157.177 313.934 Q162.987 313.934 166.042 318.54 Q169.121 323.124 169.121 331.874 Q169.121 340.601 166.042 345.207 Q162.987 349.79 157.177 349.79 Q151.366 349.79 148.288 345.207 Q145.232 340.601 145.232 331.874 Q145.232 323.124 148.288 318.54 Q151.366 313.934 157.177 313.934 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M187.338 317.638 Q183.727 317.638 181.899 321.203 Q180.093 324.744 180.093 331.874 Q180.093 338.98 181.899 342.545 Q183.727 346.087 187.338 346.087 Q190.973 346.087 192.778 342.545 Q194.607 338.98 194.607 331.874 Q194.607 324.744 192.778 321.203 Q190.973 317.638 187.338 317.638 M187.338 313.934 Q193.149 313.934 196.204 318.54 Q199.283 323.124 199.283 331.874 Q199.283 340.601 196.204 345.207 Q193.149 349.79 187.338 349.79 Q181.528 349.79 178.45 345.207 Q175.394 340.601 175.394 331.874 Q175.394 323.124 178.45 318.54 Q181.528 313.934 187.338 313.934 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M35.1993 955.099 Q31.2526 952.903 29.3747 949.847 Q27.4968 946.791 27.4968 942.654 Q27.4968 937.084 31.4117 934.06 Q35.2948 931.036 42.4881 931.036 L64.0042 931.036 L64.0042 936.925 L42.679 936.925 Q37.5546 936.925 35.072 938.739 Q32.5894 940.553 32.5894 944.277 Q32.5894 948.829 35.6131 951.47 Q38.6368 954.112 43.8567 954.112 L64.0042 954.112 L64.0042 960 L42.679 960 Q37.5228 960 35.072 961.815 Q32.5894 963.629 32.5894 967.416 Q32.5894 971.904 35.6449 974.546 Q38.6686 977.188 43.8567 977.188 L64.0042 977.188 L64.0042 983.076 L28.3562 983.076 L28.3562 977.188 L33.8944 977.188 Q30.616 975.183 29.0564 972.382 Q27.4968 969.581 27.4968 965.729 Q27.4968 961.846 29.4702 959.141 Q31.4436 956.404 35.1993 955.099 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M44.7161 888.864 L47.5806 888.864 L47.5806 915.79 Q53.6281 915.409 56.8109 912.162 Q59.9619 908.884 59.9619 903.059 Q59.9619 899.685 59.1344 896.534 Q58.3069 893.351 56.6518 890.232 L62.1899 890.232 Q63.5267 893.383 64.227 896.693 Q64.9272 900.004 64.9272 903.409 Q64.9272 911.939 59.9619 916.936 Q54.9967 921.902 46.5303 921.902 Q37.7774 921.902 32.6531 917.191 Q27.4968 912.449 27.4968 904.428 Q27.4968 897.234 32.1438 893.065 Q36.7589 888.864 44.7161 888.864 M42.9973 894.72 Q38.1912 894.784 35.3266 897.425 Q32.4621 900.035 32.4621 904.364 Q32.4621 909.266 35.2312 912.226 Q38.0002 915.154 43.0292 915.6 L42.9973 894.72 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M46.0847 863.051 Q46.0847 870.148 47.7079 872.886 Q49.3312 875.623 53.2461 875.623 Q56.3653 875.623 58.2114 873.586 Q60.0256 871.517 60.0256 867.984 Q60.0256 863.114 56.5881 860.186 Q53.1188 857.226 47.3897 857.226 L46.0847 857.226 L46.0847 863.051 M43.6657 851.37 L64.0042 851.37 L64.0042 857.226 L58.5933 857.226 Q61.8398 859.231 63.3994 862.223 Q64.9272 865.215 64.9272 869.544 Q64.9272 875.018 61.8716 878.265 Q58.7843 881.479 53.6281 881.479 Q47.6125 881.479 44.5569 877.469 Q41.5014 873.427 41.5014 865.438 L41.5014 857.226 L40.9285 857.226 Q36.8862 857.226 34.6901 859.9 Q32.4621 862.541 32.4621 867.347 Q32.4621 870.403 33.1941 873.299 Q33.9262 876.196 35.3903 878.869 L29.9795 878.869 Q28.7381 875.655 28.1334 872.631 Q27.4968 869.607 27.4968 866.743 Q27.4968 859.008 31.5072 855.189 Q35.5176 851.37 43.6657 851.37 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M42.4881 809.674 L64.0042 809.674 L64.0042 815.531 L42.679 815.531 Q37.6183 815.531 35.1038 817.504 Q32.5894 819.477 32.5894 823.424 Q32.5894 828.167 35.6131 830.904 Q38.6368 833.641 43.8567 833.641 L64.0042 833.641 L64.0042 839.529 L28.3562 839.529 L28.3562 833.641 L33.8944 833.641 Q30.6797 831.54 29.0883 828.708 Q27.4968 825.843 27.4968 822.119 Q27.4968 815.976 31.3163 812.825 Q35.1038 809.674 42.4881 809.674 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M33.8307 756.616 Q33.2578 757.603 33.0032 758.78 Q32.7167 759.926 32.7167 761.327 Q32.7167 766.292 35.9632 768.965 Q39.1779 771.607 45.2253 771.607 L64.0042 771.607 L64.0042 777.496 L28.3562 777.496 L28.3562 771.607 L33.8944 771.607 Q30.6479 769.761 29.0883 766.801 Q27.4968 763.841 27.4968 759.608 Q27.4968 759.003 27.5923 758.271 Q27.656 757.539 27.8151 756.648 L33.8307 756.616 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M44.7161 721.414 L47.5806 721.414 L47.5806 748.341 Q53.6281 747.959 56.8109 744.712 Q59.9619 741.434 59.9619 735.609 Q59.9619 732.235 59.1344 729.084 Q58.3069 725.901 56.6518 722.782 L62.1899 722.782 Q63.5267 725.933 64.227 729.243 Q64.9272 732.554 64.9272 735.959 Q64.9272 744.489 59.9619 749.486 Q54.9967 754.452 46.5303 754.452 Q37.7774 754.452 32.6531 749.741 Q27.4968 744.999 27.4968 736.978 Q27.4968 729.785 32.1438 725.615 Q36.7589 721.414 44.7161 721.414 M42.9973 727.27 Q38.1912 727.334 35.3266 729.976 Q32.4621 732.585 32.4621 736.914 Q32.4621 741.816 35.2312 744.776 Q38.0002 747.704 43.0292 748.15 L42.9973 727.27 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M28.3562 715.207 L28.3562 709.351 L56.1743 702.03 L28.3562 694.741 L28.3562 687.835 L56.1743 680.514 L28.3562 673.225 L28.3562 667.369 L64.0042 676.695 L64.0042 683.601 L34.7856 691.272 L64.0042 698.975 L64.0042 705.881 L28.3562 715.207 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M46.0847 642.288 Q46.0847 649.386 47.7079 652.123 Q49.3312 654.86 53.2461 654.86 Q56.3653 654.86 58.2114 652.823 Q60.0256 650.754 60.0256 647.221 Q60.0256 642.352 56.5881 639.423 Q53.1188 636.463 47.3897 636.463 L46.0847 636.463 L46.0847 642.288 M43.6657 630.607 L64.0042 630.607 L64.0042 636.463 L58.5933 636.463 Q61.8398 638.468 63.3994 641.46 Q64.9272 644.452 64.9272 648.781 Q64.9272 654.255 61.8716 657.502 Q58.7843 660.717 53.6281 660.717 Q47.6125 660.717 44.5569 656.706 Q41.5014 652.664 41.5014 644.675 L41.5014 636.463 L40.9285 636.463 Q36.8862 636.463 34.6901 639.137 Q32.4621 641.779 32.4621 646.585 Q32.4621 649.64 33.1941 652.537 Q33.9262 655.433 35.3903 658.107 L29.9795 658.107 Q28.7381 654.892 28.1334 651.868 Q27.4968 648.845 27.4968 645.98 Q27.4968 638.246 31.5072 634.426 Q35.5176 630.607 43.6657 630.607 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M33.8307 597.887 Q33.2578 598.874 33.0032 600.051 Q32.7167 601.197 32.7167 602.598 Q32.7167 607.563 35.9632 610.237 Q39.1779 612.878 45.2253 612.878 L64.0042 612.878 L64.0042 618.767 L28.3562 618.767 L28.3562 612.878 L33.8944 612.878 Q30.6479 611.032 29.0883 608.072 Q27.4968 605.112 27.4968 600.879 Q27.4968 600.274 27.5923 599.542 Q27.656 598.81 27.8151 597.919 L33.8307 597.887 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M33.7671 569.432 L14.479 569.432 L14.479 563.576 L64.0042 563.576 L64.0042 569.432 L58.657 569.432 Q61.8398 571.278 63.3994 574.111 Q64.9272 576.912 64.9272 580.859 Q64.9272 587.32 59.771 591.394 Q54.6147 595.436 46.212 595.436 Q37.8093 595.436 32.6531 591.394 Q27.4968 587.32 27.4968 580.859 Q27.4968 576.912 29.0564 574.111 Q30.5842 571.278 33.7671 569.432 M46.212 589.389 Q52.6732 589.389 56.3653 586.747 Q60.0256 584.074 60.0256 579.427 Q60.0256 574.78 56.3653 572.106 Q52.6732 569.432 46.212 569.432 Q39.7508 569.432 36.0905 572.106 Q32.3984 574.78 32.3984 579.427 Q32.3984 584.074 36.0905 586.747 Q39.7508 589.389 46.212 589.389 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M720.553 17.6457 Q711.641 17.6457 706.375 24.2892 Q701.149 30.9327 701.149 42.3968 Q701.149 53.8203 706.375 60.4638 Q711.641 67.1073 720.553 67.1073 Q729.465 67.1073 734.65 60.4638 Q739.876 53.8203 739.876 42.3968 Q739.876 30.9327 734.65 24.2892 Q729.465 17.6457 720.553 17.6457 M720.553 11.0023 Q733.273 11.0023 740.889 19.5497 Q748.504 28.0566 748.504 42.3968 Q748.504 56.6965 740.889 65.2439 Q733.273 73.7508 720.553 73.7508 Q707.793 73.7508 700.137 65.2439 Q692.521 56.737 692.521 42.3968 Q692.521 28.0566 700.137 19.5497 Q707.793 11.0023 720.553 11.0023 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M768.192 65.7705 L768.192 89.8329 L760.698 89.8329 L760.698 27.2059 L768.192 27.2059 L768.192 34.0924 Q770.541 30.0415 774.106 28.0971 Q777.711 26.1121 782.694 26.1121 Q790.958 26.1121 796.102 32.6746 Q801.288 39.2371 801.288 49.9314 Q801.288 60.6258 796.102 67.1883 Q790.958 73.7508 782.694 73.7508 Q777.711 73.7508 774.106 71.8063 Q770.541 69.8214 768.192 65.7705 M793.55 49.9314 Q793.55 41.7081 790.148 37.0496 Q786.785 32.3505 780.871 32.3505 Q774.957 32.3505 771.554 37.0496 Q768.192 41.7081 768.192 49.9314 Q768.192 58.1548 771.554 62.8538 Q774.957 67.5124 780.871 67.5124 Q786.785 67.5124 790.148 62.8538 Q793.55 58.1548 793.55 49.9314 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M821.016 14.324 L821.016 27.2059 L836.368 27.2059 L836.368 32.9987 L821.016 32.9987 L821.016 57.6282 Q821.016 63.1779 822.514 64.7578 Q824.054 66.3376 828.712 66.3376 L836.368 66.3376 L836.368 72.576 L828.712 72.576 Q820.084 72.576 816.803 69.3758 Q813.521 66.1351 813.521 57.6282 L813.521 32.9987 L808.053 32.9987 L808.053 27.2059 L813.521 27.2059 L813.521 14.324 L821.016 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M846.172 27.2059 L853.625 27.2059 L853.625 72.576 L846.172 72.576 L846.172 27.2059 M846.172 9.54393 L853.625 9.54393 L853.625 18.9825 L846.172 18.9825 L846.172 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M904.545 35.9153 Q907.34 30.8922 911.229 28.5022 Q915.118 26.1121 920.384 26.1121 Q927.473 26.1121 931.322 31.0947 Q935.17 36.0368 935.17 45.1919 L935.17 72.576 L927.676 72.576 L927.676 45.4349 Q927.676 38.913 925.367 35.7533 Q923.058 32.5936 918.318 32.5936 Q912.525 32.5936 909.163 36.4419 Q905.801 40.2903 905.801 46.9338 L905.801 72.576 L898.307 72.576 L898.307 45.4349 Q898.307 38.8725 895.998 35.7533 Q893.689 32.5936 888.868 32.5936 Q883.156 32.5936 879.794 36.4824 Q876.432 40.3308 876.432 46.9338 L876.432 72.576 L868.938 72.576 L868.938 27.2059 L876.432 27.2059 L876.432 34.2544 Q878.984 30.082 882.549 28.0971 Q886.114 26.1121 891.015 26.1121 Q895.957 26.1121 899.401 28.6237 Q902.884 31.1352 904.545 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M970.656 49.7694 Q961.622 49.7694 958.139 51.8354 Q954.655 53.9013 954.655 58.8839 Q954.655 62.8538 957.247 65.2034 Q959.881 67.5124 964.377 67.5124 Q970.575 67.5124 974.302 63.1374 Q978.069 58.7219 978.069 51.4303 L978.069 49.7694 L970.656 49.7694 M985.523 46.6907 L985.523 72.576 L978.069 72.576 L978.069 65.6895 Q975.517 69.8214 971.709 71.8063 Q967.901 73.7508 962.392 73.7508 Q955.425 73.7508 951.293 69.8619 Q947.201 65.9325 947.201 59.3701 Q947.201 51.7138 952.305 47.825 Q957.45 43.9361 967.618 43.9361 L978.069 43.9361 L978.069 43.2069 Q978.069 38.0623 974.666 35.2672 Q971.304 32.4315 965.187 32.4315 Q961.298 32.4315 957.612 33.3632 Q953.926 34.295 950.523 36.1584 L950.523 29.2718 Q954.614 27.692 958.463 26.9223 Q962.311 26.1121 965.957 26.1121 Q975.801 26.1121 980.662 31.2163 Q985.523 36.3204 985.523 46.6907 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1000.88 9.54393 L1008.33 9.54393 L1008.33 72.576 L1000.88 72.576 L1000.88 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1023.93 27.2059 L1031.38 27.2059 L1031.38 72.576 L1023.93 72.576 L1023.93 27.2059 M1023.93 9.54393 L1031.38 9.54393 L1031.38 18.9825 L1023.93 18.9825 L1023.93 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1054.35 14.324 L1054.35 27.2059 L1069.7 27.2059 L1069.7 32.9987 L1054.35 32.9987 L1054.35 57.6282 Q1054.35 63.1779 1055.85 64.7578 Q1057.39 66.3376 1062.04 66.3376 L1069.7 66.3376 L1069.7 72.576 L1062.04 72.576 Q1053.42 72.576 1050.13 69.3758 Q1046.85 66.1351 1046.85 57.6282 L1046.85 32.9987 L1041.38 32.9987 L1041.38 27.2059 L1046.85 27.2059 L1046.85 14.324 L1054.35 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1098.38 76.7889 Q1095.22 84.8907 1092.22 87.3618 Q1089.23 89.8329 1084.2 89.8329 L1078.25 89.8329 L1078.25 83.5945 L1082.62 83.5945 Q1085.7 83.5945 1087.4 82.1361 Q1089.1 80.6778 1091.17 75.2496 L1092.51 71.8468 L1074.16 27.2059 L1082.06 27.2059 L1096.23 62.6918 L1110.41 27.2059 L1118.31 27.2059 L1098.38 76.7889 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1149.62 27.2059 L1157.52 27.2059 L1171.7 65.2844 L1185.88 27.2059 L1193.78 27.2059 L1176.77 72.576 L1166.64 72.576 L1149.62 27.2059 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1232.99 28.5427 L1232.99 35.5912 Q1229.83 33.9709 1226.43 33.1607 Q1223.03 32.3505 1219.38 32.3505 Q1213.83 32.3505 1211.04 34.0519 Q1208.28 35.7533 1208.28 39.156 Q1208.28 41.7486 1210.27 43.2475 Q1212.25 44.7058 1218.25 46.0426 L1220.8 46.6097 Q1228.74 48.3111 1232.06 51.4303 Q1235.42 54.509 1235.42 60.0587 Q1235.42 66.3781 1230.4 70.0644 Q1225.42 73.7508 1216.67 73.7508 Q1213.02 73.7508 1209.05 73.0216 Q1205.12 72.3329 1200.75 70.9151 L1200.75 63.2184 Q1204.88 65.3654 1208.89 66.4591 Q1212.9 67.5124 1216.83 67.5124 Q1222.1 67.5124 1224.93 65.73 Q1227.77 63.9071 1227.77 60.6258 Q1227.77 57.5877 1225.7 55.9673 Q1223.68 54.3469 1216.75 52.8481 L1214.16 52.2405 Q1207.23 50.7821 1204.15 47.7845 Q1201.07 44.7463 1201.07 39.4801 Q1201.07 33.0797 1205.61 29.5959 Q1210.15 26.1121 1218.49 26.1121 Q1222.62 26.1121 1226.27 26.7198 Q1229.91 27.3274 1232.99 28.5427 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1248.35 62.2867 L1256.89 62.2867 L1256.89 72.576 L1248.35 72.576 L1248.35 62.2867 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1345.65 16.7545 L1345.65 25.383 Q1341.52 21.5346 1336.82 19.6307 Q1332.16 17.7268 1326.89 17.7268 Q1316.52 17.7268 1311.01 24.0867 Q1305.5 30.4061 1305.5 42.3968 Q1305.5 54.3469 1311.01 60.7069 Q1316.52 67.0263 1326.89 67.0263 Q1332.16 67.0263 1336.82 65.1223 Q1341.52 63.2184 1345.65 59.3701 L1345.65 67.9175 Q1341.35 70.8341 1336.53 72.2924 Q1331.75 73.7508 1326.41 73.7508 Q1312.67 73.7508 1304.77 65.3654 Q1296.88 56.9395 1296.88 42.3968 Q1296.88 27.8135 1304.77 19.4281 Q1312.67 11.0023 1326.41 11.0023 Q1331.83 11.0023 1336.61 12.4606 Q1341.44 13.8784 1345.65 16.7545 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1375.54 32.4315 Q1369.55 32.4315 1366.06 37.1306 Q1362.58 41.7891 1362.58 49.9314 Q1362.58 58.0738 1366.02 62.7728 Q1369.51 67.4314 1375.54 67.4314 Q1381.5 67.4314 1384.98 62.7323 Q1388.47 58.0333 1388.47 49.9314 Q1388.47 41.8701 1384.98 37.1711 Q1381.5 32.4315 1375.54 32.4315 M1375.54 26.1121 Q1385.27 26.1121 1390.82 32.4315 Q1396.37 38.7509 1396.37 49.9314 Q1396.37 61.0714 1390.82 67.4314 Q1385.27 73.7508 1375.54 73.7508 Q1365.78 73.7508 1360.23 67.4314 Q1354.72 61.0714 1354.72 49.9314 Q1354.72 38.7509 1360.23 32.4315 Q1365.78 26.1121 1375.54 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1444.04 35.9153 Q1446.84 30.8922 1450.73 28.5022 Q1454.62 26.1121 1459.88 26.1121 Q1466.97 26.1121 1470.82 31.0947 Q1474.67 36.0368 1474.67 45.1919 L1474.67 72.576 L1467.18 72.576 L1467.18 45.4349 Q1467.18 38.913 1464.87 35.7533 Q1462.56 32.5936 1457.82 32.5936 Q1452.02 32.5936 1448.66 36.4419 Q1445.3 40.2903 1445.3 46.9338 L1445.3 72.576 L1437.81 72.576 L1437.81 45.4349 Q1437.81 38.8725 1435.5 35.7533 Q1433.19 32.5936 1428.37 32.5936 Q1422.66 32.5936 1419.29 36.4824 Q1415.93 40.3308 1415.93 46.9338 L1415.93 72.576 L1408.44 72.576 L1408.44 27.2059 L1415.93 27.2059 L1415.93 34.2544 Q1418.48 30.082 1422.05 28.0971 Q1425.61 26.1121 1430.51 26.1121 Q1435.46 26.1121 1438.9 28.6237 Q1442.38 31.1352 1444.04 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1496.75 65.7705 L1496.75 89.8329 L1489.25 89.8329 L1489.25 27.2059 L1496.75 27.2059 L1496.75 34.0924 Q1499.1 30.0415 1502.66 28.0971 Q1506.27 26.1121 1511.25 26.1121 Q1519.51 26.1121 1524.66 32.6746 Q1529.84 39.2371 1529.84 49.9314 Q1529.84 60.6258 1524.66 67.1883 Q1519.51 73.7508 1511.25 73.7508 Q1506.27 73.7508 1502.66 71.8063 Q1499.1 69.8214 1496.75 65.7705 M1522.11 49.9314 Q1522.11 41.7081 1518.7 37.0496 Q1515.34 32.3505 1509.43 32.3505 Q1503.51 32.3505 1500.11 37.0496 Q1496.75 41.7081 1496.75 49.9314 Q1496.75 58.1548 1500.11 62.8538 Q1503.51 67.5124 1509.43 67.5124 Q1515.34 67.5124 1518.7 62.8538 Q1522.11 58.1548 1522.11 49.9314 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1541.43 54.671 L1541.43 27.2059 L1548.88 27.2059 L1548.88 54.3874 Q1548.88 60.8284 1551.39 64.0691 Q1553.91 67.2693 1558.93 67.2693 Q1564.96 67.2693 1568.45 63.421 Q1571.97 59.5726 1571.97 52.9291 L1571.97 27.2059 L1579.43 27.2059 L1579.43 72.576 L1571.97 72.576 L1571.97 65.6084 Q1569.26 69.7404 1565.65 71.7658 Q1562.09 73.7508 1557.35 73.7508 Q1549.53 73.7508 1545.48 68.8897 Q1541.43 64.0286 1541.43 54.671 M1560.18 26.1121 L1560.18 26.1121 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1602.15 14.324 L1602.15 27.2059 L1617.5 27.2059 L1617.5 32.9987 L1602.15 32.9987 L1602.15 57.6282 Q1602.15 63.1779 1603.65 64.7578 Q1605.19 66.3376 1609.85 66.3376 L1617.5 66.3376 L1617.5 72.576 L1609.85 72.576 Q1601.22 72.576 1597.94 69.3758 Q1594.66 66.1351 1594.66 57.6282 L1594.66 32.9987 L1589.19 32.9987 L1589.19 27.2059 L1594.66 27.2059 L1594.66 14.324 L1602.15 14.324 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1666.12 48.0275 L1666.12 51.6733 L1631.84 51.6733 Q1632.33 59.3701 1636.46 63.421 Q1640.63 67.4314 1648.05 67.4314 Q1652.34 67.4314 1656.35 66.3781 Q1660.4 65.3249 1664.37 63.2184 L1664.37 70.267 Q1660.36 71.9684 1656.15 72.8596 Q1651.94 73.7508 1647.6 73.7508 Q1636.75 73.7508 1630.39 67.4314 Q1624.07 61.1119 1624.07 50.3365 Q1624.07 39.1965 1630.06 32.6746 Q1636.1 26.1121 1646.31 26.1121 Q1655.46 26.1121 1660.77 32.0264 Q1666.12 37.9003 1666.12 48.0275 M1658.66 45.84 Q1658.58 39.7232 1655.22 36.0774 Q1651.9 32.4315 1646.39 32.4315 Q1640.15 32.4315 1636.38 35.9558 Q1632.65 39.4801 1632.09 45.8805 L1658.66 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1696.66 12.096 L1747.82 12.096 L1747.82 18.9825 L1726.35 18.9825 L1726.35 72.576 L1718.13 72.576 L1718.13 18.9825 L1696.66 18.9825 L1696.66 12.096 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1752.85 27.2059 L1760.3 27.2059 L1760.3 72.576 L1752.85 72.576 L1752.85 27.2059 M1752.85 9.54393 L1760.3 9.54393 L1760.3 18.9825 L1752.85 18.9825 L1752.85 9.54393 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1811.22 35.9153 Q1814.01 30.8922 1817.9 28.5022 Q1821.79 26.1121 1827.06 26.1121 Q1834.15 26.1121 1838 31.0947 Q1841.84 36.0368 1841.84 45.1919 L1841.84 72.576 L1834.35 72.576 L1834.35 45.4349 Q1834.35 38.913 1832.04 35.7533 Q1829.73 32.5936 1824.99 32.5936 Q1819.2 32.5936 1815.84 36.4419 Q1812.47 40.2903 1812.47 46.9338 L1812.47 72.576 L1804.98 72.576 L1804.98 45.4349 Q1804.98 38.8725 1802.67 35.7533 Q1800.36 32.5936 1795.54 32.5936 Q1789.83 32.5936 1786.47 36.4824 Q1783.11 40.3308 1783.11 46.9338 L1783.11 72.576 L1775.61 72.576 L1775.61 27.2059 L1783.11 27.2059 L1783.11 34.2544 Q1785.66 30.082 1789.22 28.0971 Q1792.79 26.1121 1797.69 26.1121 Q1802.63 26.1121 1806.07 28.6237 Q1809.56 31.1352 1811.22 35.9153 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M1895.52 48.0275 L1895.52 51.6733 L1861.25 51.6733 Q1861.73 59.3701 1865.87 63.421 Q1870.04 67.4314 1877.45 67.4314 Q1881.74 67.4314 1885.76 66.3781 Q1889.81 65.3249 1893.78 63.2184 L1893.78 70.267 Q1889.77 71.9684 1885.55 72.8596 Q1881.34 73.7508 1877.01 73.7508 Q1866.15 73.7508 1859.79 67.4314 Q1853.47 61.1119 1853.47 50.3365 Q1853.47 39.1965 1859.46 32.6746 Q1865.5 26.1121 1875.71 26.1121 Q1884.86 26.1121 1890.17 32.0264 Q1895.52 37.9003 1895.52 48.0275 M1888.06 45.84 Q1887.98 39.7232 1884.62 36.0774 Q1881.3 32.4315 1875.79 32.4315 Q1869.55 32.4315 1865.78 35.9558 Q1862.06 39.4801 1861.49 45.8805 L1888.06 45.84 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip262)\" d=\"M295.211 1386.4 L790.663 1331.91 L790.663 1320.12 L295.211 1382  Z\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"0.2\"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"295.211,1384.2 790.663,1326.02 \"/>\n",
       "<path clip-path=\"url(#clip262)\" d=\"M1289.58 634.444 L2292.83 187.149 L1202.7 1049.28 L1202.7 1037.62 L2292.83 160.256 L1289.58 609.067  Z\" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"0.2\"/>\n",
       "<polyline clip-path=\"url(#clip262)\" style=\"stroke:#e26f46; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1289.58,621.756 2292.83,173.703 1202.7,1043.45 \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M305.865 322.316 L617.057 322.316 L617.057 166.796 L305.865 166.796  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"305.865,322.316 617.057,322.316 617.057,166.796 305.865,166.796 305.865,322.316 \"/>\n",
       "<polyline clip-path=\"url(#clip260)\" style=\"stroke:#009af9; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"329.393,218.636 470.558,218.636 \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M494.085 209.99 L498.599 209.99 L506.701 231.749 L514.803 209.99 L519.316 209.99 L509.594 235.916 L503.807 235.916 L494.085 209.99 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M525.196 209.99 L529.455 209.99 L529.455 235.916 L525.196 235.916 L525.196 209.99 M525.196 199.897 L529.455 199.897 L529.455 205.291 L525.196 205.291 L525.196 199.897 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip260)\" style=\"stroke:#e26f46; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"329.393,270.476 470.558,270.476 \"/>\n",
       "<path clip-path=\"url(#clip260)\" d=\"M512.858 274.816 Q512.858 270.117 510.914 267.455 Q508.992 264.77 505.613 264.77 Q502.233 264.77 500.289 267.455 Q498.367 270.117 498.367 274.816 Q498.367 279.515 500.289 282.2 Q502.233 284.862 505.613 284.862 Q508.992 284.862 510.914 282.2 Q512.858 279.515 512.858 274.816 M498.367 265.765 Q499.71 263.45 501.747 262.339 Q503.807 261.205 506.654 261.205 Q511.377 261.205 514.316 264.955 Q517.279 268.705 517.279 274.816 Q517.279 280.927 514.316 284.677 Q511.377 288.427 506.654 288.427 Q503.807 288.427 501.747 287.316 Q499.71 286.182 498.367 283.867 L498.367 287.756 L494.085 287.756 L494.085 251.737 L498.367 251.737 L498.367 265.765 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M524.34 251.737 L528.599 251.737 L528.599 287.756 L524.34 287.756 L524.34 251.737 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M557.21 295.626 L557.21 298.936 L532.58 298.936 L532.58 295.626 L557.21 295.626 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M558.159 261.83 L562.673 261.83 L570.775 283.589 L578.876 261.83 L583.39 261.83 L573.668 287.756 L567.881 287.756 L558.159 261.83 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /><path clip-path=\"url(#clip260)\" d=\"M589.27 261.83 L593.529 261.83 L593.529 287.756 L589.27 287.756 L589.27 261.83 M589.27 251.737 L593.529 251.737 L593.529 257.131 L589.27 257.131 L589.27 251.737 Z\" fill=\"#000000\" fill-rule=\"nonzero\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RoverWorld.plot_optimality_vs_compute(results, dir = dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3abf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.0",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
